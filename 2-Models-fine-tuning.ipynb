{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46641326-1e71-4d7a-a13b-e3584ab5cb1f",
   "metadata": {
    "id": "46641326-1e71-4d7a-a13b-e3584ab5cb1f"
   },
   "source": [
    "# Model fine-tuning\n",
    "### XLM-RoBERTa and mDeBERTa models fine-tuning on MultiCW and OOD datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb7fd0d-9d7e-43be-9257-644125af64e9",
   "metadata": {
    "id": "3eb7fd0d-9d7e-43be-9257-644125af64e9"
   },
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9164a8d-2e16-45c1-b052-79ff7da7e8cc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Setup project paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4b1d6c59d2b5ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from os.path import join, exists\n",
    "from py_markdown_table.markdown_table import markdown_table\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Enable tqdm for pandas\n",
    "tqdm.pandas()\n",
    "\n",
    "# ANSI Highlighting: https://stackoverflow.com/a/21786287\n",
    "h_red = '\\x1b[1;30;41m'\n",
    "h_green = '\\x1b[1;30;42m'\n",
    "h_yellow = '\\x1b[1;30;43m'\n",
    "h_stop = '\\x1b[0m'\n",
    "\n",
    "## Setup project paths:\n",
    "project_path = os.getcwd()\n",
    "models_path = join(project_path, \"Models\")\n",
    "\n",
    "datasets_path = join(project_path, \"Source datasets\")\n",
    "multicw_path = join(project_path, 'Final-dataset')\n",
    "multiclaim_path = join(datasets_path, \"MultiClaim\")\n",
    "lesa_dst_dir = join(datasets_path, 'LESA-EACL-2021')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb31e5eb4ab1684",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Datasets\n",
    "Loading the MultiCW and OOD datasets for the purpose of models fine-tuning and their evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "585cff8b46c36f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded MultiCW:\n",
      "Train set: 88001\n",
      "Dev set: 14823\n",
      "Test set: 14823\n",
      "Out-of-dist set: 27761\n"
     ]
    }
   ],
   "source": [
    "# Load MultiCW model\n",
    "import pandas as pd\n",
    "from os.path import join\n",
    "languages = pd.read_csv(join('Final-dataset', 'multicw-full.csv'))['lang'].unique()\n",
    "\n",
    "multicw_path = join(\"Final-dataset\")\n",
    "multicw_train = pd.read_csv(join(multicw_path, \"multicw-train.csv\")).astype({'label':'int'})\n",
    "multicw_dev = pd.read_csv(join(multicw_path, \"multicw-dev.csv\")).astype({'label':'int'})\n",
    "multicw_test = pd.read_csv(join(multicw_path, \"multicw-test.csv\")).astype({'label':'int'})\n",
    "multicw_test = pd.read_csv(join(multicw_path, \"multicw-test.csv\")).astype({'text':'str'})\n",
    "multicw_ood = pd.read_csv(join(multicw_path, \"multicw-ood.csv\")).astype({'label':'int'})\n",
    "multicw_ood['style'] = multicw_ood['style'].replace('structured', 'struc')\n",
    "multicw_ood['text'] = multicw_ood['text'].fillna(\"\").astype(str)\n",
    "\n",
    "print(f'Loaded MultiCW:')\n",
    "print(f'Train set: {multicw_train.shape[0]}')\n",
    "print(f'Dev set: {multicw_dev.shape[0]}')\n",
    "print(f'Test set: {multicw_test.shape[0]}')\n",
    "print(f'Out-of-dist set: {multicw_ood.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07373bf5-a7a4-4a8f-a93a-d1054d4b07cf",
   "metadata": {
    "id": "07373bf5-a7a4-4a8f-a93a-d1054d4b07cf"
   },
   "source": [
    "## Models\n",
    "Implementation of the used models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e120cb5dc7290406",
   "metadata": {},
   "source": [
    "### XLM-RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1nnytAhaNAny",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1nnytAhaNAny",
    "outputId": "8cddf7b0-303c-4de4-d926-24ecd5edbd25"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-01 13:45:57.897642: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-10-01 13:45:57.922397: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-10-01 13:45:57.922454: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-10-01 13:45:57.951995: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-01 13:45:58.731523: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/hyben/.conda/envs/MultiCW-finetune/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import warnings\n",
    "from typing import Callable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import keras_hub\n",
    "import keras\n",
    "\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from pandas import DataFrame\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.optimizers import Adam\n",
    "from tqdm import tqdm\n",
    "from transformers import BertTokenizer, AutoTokenizer\n",
    "\n",
    "\n",
    "class XLMRobertaModel():\n",
    "    \"\"\" Model finetuning and inference on the LESA dataset using XLMRoberta \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.max_len = 256\n",
    "        self.batch_size = 32\n",
    "\n",
    "        self.final_model = None\n",
    "\n",
    "        self.preprocessor = keras_hub.models.TextClassifierPreprocessor.from_preset(\n",
    "            'xlm_roberta_base_multi',\n",
    "            sequence_length=self.max_len\n",
    "        )\n",
    "\n",
    "    def load_model(self, model_name) -> bool:\n",
    "        try:\n",
    "            # 1. Instantiate the model with the known preset (architecture)\n",
    "            self.final_model = keras_hub.models.XLMRobertaTextClassifier.from_preset(\n",
    "                'xlm_roberta_base_multi',\n",
    "                num_classes=2,\n",
    "                preprocessor=self.preprocessor,\n",
    "                dropout=0.2\n",
    "            )\n",
    "    \n",
    "            # 2. Load the weights manually from the path\n",
    "            weights_path = os.path.join('Models', f'{model_name}.weights.h5')\n",
    "            self.final_model.load_weights(weights_path)\n",
    "    \n",
    "            print('Model loaded successfully.')\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def detect_claims(self, test_set: DataFrame, verbose=False) -> tuple:\n",
    "        \"\"\"Performs inference on the testing data and evaluates results.\"\"\"\n",
    "\n",
    "        print('Running classification:')\n",
    "        metrics = self.final_model.predict(x=test_set['text'].to_numpy(), batch_size=self.batch_size)\n",
    "\n",
    "        # Testing\n",
    "        results = np.argmax(metrics, axis=1)\n",
    "        print('Done.')\n",
    "        # Print sentences with classifications\n",
    "        if verbose:\n",
    "            for i, text in enumerate(test_set['text']):\n",
    "                print(\"LESA classification: '{text}' {c} a claim.\".\n",
    "                      format(text=text, c=gh_start + \"is\" if results[i] == 1 else rh_start + \"is not\") + h_stop)\n",
    "\n",
    "        # Compare against ground-truth\n",
    "        ground_truth = test_set['label'].to_numpy()\n",
    "        report = classification_report(ground_truth, results, output_dict=True)\n",
    "        report_str = str(classification_report(ground_truth, results))\n",
    "\n",
    "        return report, report_str\n",
    "\n",
    "    def train_model(self, train_set: DataFrame, dev_set: DataFrame, epochs=1, learn_rate=3e-5, model_name='', lang='en'):\n",
    "        \"\"\"\n",
    "        Train the XLMRoberta model with the given parameters.\n",
    "\n",
    "        :param learn_rate: Learning rate.\n",
    "        :param train_set: Training dataset.\n",
    "        :param dev_set: Validation dataset.\n",
    "        :param epochs: Number of training epochs.\n",
    "        :param model_name: Model will be saved to the directory named by this value.If left blank, the model won't save.\n",
    "        :param lang: Training dataset language(s). Needed for naming conventions.\n",
    "        :return: Trained model.\n",
    "        \"\"\"\n",
    "\n",
    "        model_name_path = f\"{model_name}-{lang}-{epochs}e\"\n",
    "        path = os.path.join('Models', 'LESA', 'models', model_name_path)\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "\n",
    "\n",
    "        self.final_model = keras_hub.models.XLMRobertaTextClassifier.from_preset(\n",
    "            'xlm_roberta_base_multi',\n",
    "            num_classes=len(train_set['label'].unique()),\n",
    "            preprocessor=self.preprocessor,\n",
    "            dropout=0.2\n",
    "        )\n",
    "\n",
    "        for layer in self.final_model.layers:\n",
    "            layer.trainable = True\n",
    "\n",
    "        self.final_model.compile(\n",
    "            loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            optimizer=keras.optimizers.Adam(learn_rate),\n",
    "            jit_compile=True,\n",
    "        )\n",
    "\n",
    "        self.final_model.fit(x=train_set['text'].to_numpy(), y=train_set['label'].to_numpy(), batch_size=self.batch_size,\n",
    "                             epochs=epochs, validation_data=(dev_set['text'].to_numpy(), dev_set['label'].to_numpy()))\n",
    "\n",
    "        model_save_path = os.path.join(path, 'model.keras')\n",
    "        self.final_model.save(model_save_path)\n",
    "\n",
    "    def inference(self, texts: list[str]) -> list[bool]:\n",
    "        \"\"\"Returns a list of booleans: True if classified as a claim (class 1), else False.\"\"\"\n",
    "        if not isinstance(texts, list):\n",
    "            raise ValueError(\"Input must be a list of strings.\")\n",
    "        if not all(isinstance(t, str) for t in texts):\n",
    "            raise ValueError(\"All items in input list must be strings.\")\n",
    "    \n",
    "        predictions = self.final_model.predict(texts)  # Must be list[str]\n",
    "        classifications = np.argmax(predictions, axis=1)  # shape (batch_size,)\n",
    "        \n",
    "        return (classifications == 1).tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb81e0d1219ede9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### mDeBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "o-kYQPkJyLcm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o-kYQPkJyLcm",
    "outputId": "2676b48b-f4ec-415d-e5af-4d60d6d48d01"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import warnings\n",
    "from typing import Callable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import keras_hub\n",
    "import keras\n",
    "\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from pandas import DataFrame\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.optimizers import Adam\n",
    "from tqdm import tqdm\n",
    "from transformers import BertTokenizer, AutoTokenizer\n",
    "from tensorflow.keras.optimizers.schedules import CosineDecay\n",
    "\n",
    "\n",
    "class MDeBertaModel():\n",
    "    \"\"\"  \"\"\"\n",
    "\n",
    "    def __init__(self, model_name=''):\n",
    "        self.max_len = 256\n",
    "        self.batch_size = 32\n",
    "        self.final_model = None\n",
    "        \n",
    "        self.preprocessor = keras_hub.models.TextClassifierPreprocessor.from_preset(\n",
    "            'deberta_v3_base_multi',\n",
    "            sequence_length=self.max_len\n",
    "        )\n",
    "\n",
    "    def load_model(self, model_name) -> bool:\n",
    "        try:\n",
    "            model_path = os.path.join('Models', model_name + '.keras')\n",
    "    \n",
    "            if not os.path.exists(model_path):\n",
    "                raise FileNotFoundError(f\"Saved model not found at: {model_path}\")\n",
    "    \n",
    "            print(f\"Loading full model from: {model_path}\")\n",
    "            self.final_model = keras.models.load_model(model_path)\n",
    "            print(\"Model loaded successfully.\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model: {str(e)}\")\n",
    "            return False\n",
    "            \n",
    "    def detect_claims(self, test_set: DataFrame, verbose=False) -> tuple:\n",
    "        \"\"\"Performs inference on the testing data and evaluates results.\"\"\"\n",
    "\n",
    "        print('Running classification:')\n",
    "        metrics = self.final_model.predict(x=test_set['text'].to_numpy(), batch_size=self.batch_size)\n",
    "\n",
    "        # Testing\n",
    "        results = np.argmax(metrics, axis=1)\n",
    "        print('Done.')\n",
    "        # Print sentences with classifications\n",
    "        if verbose:\n",
    "            for i, text in enumerate(test_set['text']):\n",
    "                print(\"LESA classification: '{text}' {c} a claim.\".\n",
    "                      format(text=text, c=gh_start + \"is\" if results[i] == 1 else rh_start + \"is not\") + h_stop)\n",
    "\n",
    "        # Compare against ground-truth\n",
    "        ground_truth = test_set['label'].to_numpy()\n",
    "        report = classification_report(ground_truth, results, output_dict=True)\n",
    "        report_str = str(classification_report(ground_truth, results))\n",
    "\n",
    "        return report, report_str\n",
    "\n",
    "    def train_model(self, train_set: DataFrame, dev_set: DataFrame, epochs=1, learn_rate=3e-5, model_name='', lang='en', final_learn_rate_fraction=0.5):\n",
    "        \"\"\"\n",
    "        Train the mDeBerta model with the given parameters.\n",
    "        :param learn_rate: Learning rate.\n",
    "        :param train_set: Training dataset.\n",
    "        :param dev_set: Validation dataset.\n",
    "        :param epochs: Number of training epochs.\n",
    "        :param model_name: Model will be saved to the directory named by this value.If left blank, the model won't save.\n",
    "        :param lang: Training dataset language(s). Needed for naming conventions.\n",
    "        :return: Trained model.\n",
    "        \"\"\"\n",
    "\n",
    "        self.final_model = keras_hub.models.DebertaV3Classifier.from_preset(\n",
    "            'deberta_v3_base_multi',\n",
    "            num_classes=len(set(train_set['label'].unique())),\n",
    "            preprocessor=self.preprocessor,\n",
    "            dropout=0.2\n",
    "        )\n",
    "\n",
    "        for layer in self.final_model.layers:\n",
    "            layer.trainable = True\n",
    "\n",
    "        initial_learning_rate = learn_rate\n",
    "        decay_steps = int(len(train_set) // self.batch_size * epochs)   # Number of steps over which the decay is applied\n",
    "        alpha = final_learn_rate_fraction  # Minimum learning rate as a fraction of initial_learning_rate\n",
    "\n",
    "        lr_schedule = CosineDecay(\n",
    "            initial_learning_rate=initial_learning_rate,\n",
    "            decay_steps=decay_steps,\n",
    "            alpha=alpha\n",
    "        )\n",
    "\n",
    "        self.final_model.compile(\n",
    "            loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "            jit_compile=True\n",
    "        )\n",
    "\n",
    "        self.final_model.fit(x=train_set['text'].to_numpy(), y=train_set['label'].to_numpy(), batch_size=self.batch_size,\n",
    "                             epochs=epochs, validation_data=(dev_set['text'].to_numpy(), dev_set['label'].to_numpy()))\n",
    "\n",
    "        model_save_path = os.path.join(path, f\"{model_name}-{lang}-{epochs}e.keras\")\n",
    "        self.final_model.save(model_save_path)\n",
    "        \n",
    "    def inference(self, texts: list[str]) -> list[bool]:\n",
    "        \"\"\"Returns a list of booleans: True if classified as a claim (class 1), else False.\"\"\"\n",
    "        if not isinstance(texts, list):\n",
    "            raise ValueError(\"Input must be a list of strings.\")\n",
    "        if not all(isinstance(t, str) for t in texts):\n",
    "            raise ValueError(\"All items in input list must be strings.\")\n",
    "    \n",
    "        predictions = self.final_model.predict(texts)  # Must be list[str]\n",
    "        classifications = np.argmax(predictions, axis=1)  # shape (batch_size,)\n",
    "        \n",
    "        return (classifications == 1).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5104ea-1327-4fbd-bd6b-edcbec967bd4",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dd05912ce3053e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Models fine-tuning on MultiCW dataset\n",
    "- Fine-tuning of xlm-RoBERTa, mDeBERTa anb LESA models on MultiCW train set\n",
    "- Evaluation on MultiCW test set\n",
    "\n",
    "#### XLM-RoBERTa model:\n",
    "<table>\n",
    "<tr>\n",
    "<td>\n",
    "\n",
    "| Class            | Precision | Recall | F1-score | Support   |\n",
    "| ---------------- | --------- | ------ | -------- | --------- |\n",
    "| 0                | 0.87      | 0.88   | 0.87     | 9269      |\n",
    "| 1                | 0.88      | 0.87   | 0.87     | 9175      |\n",
    "| **Accuracy**     |           |        | **0.87** | **18444** |\n",
    "| **Macro avg**    | 0.87      | 0.87   | 0.87     | 18444     |\n",
    "| **Weighted avg** | 0.87      | 0.87   | 0.87     | 18444     |\n",
    "                    MultiCW Overall.\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "| Class            | Precision | Recall | F1-score | Support  |\n",
    "| ---------------- | --------- | ------ | -------- | -------- |\n",
    "| 0                | 0.81      | 0.82   | 0.81     | 4744     |\n",
    "| 1                | 0.81      | 0.80   | 0.81     | 4650     |\n",
    "| **Accuracy**     |           |        | **0.81** | **9394** |\n",
    "| **Macro avg**    | 0.81      | 0.81   | 0.81     | 9394     |\n",
    "| **Weighted avg** | 0.81      | 0.81   | 0.81     | 9394     |\n",
    "                MultiCW Noisy Part.\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "| Class            | Precision | Recall | F1-score | Support  |\n",
    "| ---------------- | --------- | ------ | -------- | -------- |\n",
    "| 0                | 0.93      | 0.94   | 0.94     | 4525     |\n",
    "| 1                | 0.94      | 0.93   | 0.93     | 4525     |\n",
    "| **Accuracy**     |           |        | **0.93** | **9050** |\n",
    "| **Macro avg**    | 0.93      | 0.93   | 0.93     | 9050     |\n",
    "| **Weighted avg** | 0.93      | 0.93   | 0.93     | 9050     |\n",
    "                MultiCW Structured Part.\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "#### mDeBERTa model:\n",
    "<table>\n",
    "<tr>\n",
    "<td>\n",
    "\n",
    "| Class            | Precision | Recall | F1-score | Support   |\n",
    "| ---------------- | --------- | ------ | -------- | --------- |\n",
    "| 0                | 0.89      | 0.86   | 0.87     | 9269      |\n",
    "| 1                | 0.86      | 0.89   | 0.88     | 9175      |\n",
    "| **Accuracy**     |           |        | **0.88** | **18444** |\n",
    "| **Macro avg**    | 0.88      | 0.88   | 0.88     | 18444     |\n",
    "| **Weighted avg** | 0.88      | 0.88   | 0.88     | 18444     |\n",
    "                    MultiCW Overall.\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "| Class            | Precision | Recall | F1-score | Support  |\n",
    "| ---------------- | --------- | ------ | -------- | -------- |\n",
    "| 0                | 0.84      | 0.80   | 0.82     | 4744     |\n",
    "| 1                | 0.81      | 0.84   | 0.82     | 4650     |\n",
    "| **Accuracy**     |           |        | **0.82** | **9394** |\n",
    "| **Macro avg**    | 0.82      | 0.82   | 0.82     | 9394     |\n",
    "| **Weighted avg** | 0.82      | 0.82   | 0.82     | 9394     |\n",
    "                MultiCW Noisy Part.\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "| Class            | Precision | Recall | F1-score | Support  |\n",
    "| ---------------- | --------- | ------ | -------- | -------- |\n",
    "| 0                | 0.95      | 0.91   | 0.93     | 4525     |\n",
    "| 1                | 0.92      | 0.95   | 0.93     | 4525     |\n",
    "| **Accuracy**     |           |        | **0.93** | **9050** |\n",
    "| **Macro avg**    | 0.93      | 0.93   | 0.93     | 9050     |\n",
    "| **Weighted avg** | 0.93      | 0.93   | 0.93     | 9050     |\n",
    "                MultiCW Structured Part.\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c67e86a4-96fa-4fc9-bc1f-5d7ee253bf73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;42mXLM-RoBERTa model:\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-01 07:29:50.732261: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-09-01 07:29:50.787211: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-09-01 07:29:50.791843: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-09-01 07:29:50.796114: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-09-01 07:29:50.800168: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-09-01 07:29:50.802899: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-09-01 07:29:50.937409: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-09-01 07:29:50.939480: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-09-01 07:29:50.941555: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-09-01 07:29:50.943717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4134 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2025-09-01 07:29:53.127788: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 768006144 exceeds 10% of free system memory.\n",
      "2025-09-01 07:29:55.067900: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 768006144 exceeds 10% of free system memory.\n",
      "/home/hyben/.conda/envs/MultiCW-finetune/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 401 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n",
      "\u001b[1;30;42mMultiCW overall:\u001b[0m\n",
      "Running classification:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1756704598.034464 1441906 service.cc:145] XLA service 0x7fc4b002cdc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1756704598.034524 1441906 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "2025-09-01 07:29:58.117842: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-01 07:29:58.332846: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1756704599.611815 1441982 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_2670', 348 bytes spill stores, 356 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/577\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m34:16\u001b[0m 4s/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1756704600.414404 1441906 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m576/577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 195ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1756704714.817255 1442071 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_2688', 40 bytes spill stores, 40 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m577/577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 200ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.87      9269\n",
      "           1       0.88      0.87      0.87      9175\n",
      "\n",
      "    accuracy                           0.87     18444\n",
      "   macro avg       0.87      0.87      0.87     18444\n",
      "weighted avg       0.87      0.87      0.87     18444\n",
      "\n",
      "Running classification:\n",
      "\u001b[1m293/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 198ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1756704776.305381 1442191 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_2688', 60 bytes spill stores, 60 bytes spill loads\n",
      "\n",
      "I0000 00:00:1756704776.697019 1442190 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_2688', 372 bytes spill stores, 380 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 206ms/step\n",
      "Done.\n",
      "\u001b[1;30;43mMultiCW Noisy Part:\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      4744\n",
      "           1       0.81      0.80      0.81      4650\n",
      "\n",
      "    accuracy                           0.81      9394\n",
      "   macro avg       0.81      0.81      0.81      9394\n",
      "weighted avg       0.81      0.81      0.81      9394\n",
      "\n",
      "Running classification:\n",
      "\u001b[1m282/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 198ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1756704835.888722 1442280 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_2688', 60 bytes spill stores, 60 bytes spill loads\n",
      "\n",
      "I0000 00:00:1756704836.010144 1442286 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_2688', 352 bytes spill stores, 356 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 206ms/step\n",
      "Done.\n",
      "\u001b[1;30;43mMultiCW Structured Part:\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94      4525\n",
      "           1       0.94      0.93      0.93      4525\n",
      "\n",
      "    accuracy                           0.93      9050\n",
      "   macro avg       0.93      0.93      0.93      9050\n",
      "weighted avg       0.93      0.93      0.93      9050\n",
      "\n",
      "\u001b[1;30;42mmDBERTa model:\u001b[0m\n",
      "Loading full model from: Models/mdb-multicw-2e6-5e.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyben/.conda/envs/MultiCW-finetune/lib/python3.10/site-packages/keras/src/saving/serialization_lib.py:734: UserWarning: `compile()` was not called as part of model loading because the model's `compile()` method is custom. All subclassed Models that have `compile()` overridden should also override `get_compile_config()` and `compile_from_config(config)`. Alternatively, you can call `compile()` manually after loading.\n",
      "  instance.compile_from_config(compile_config)\n",
      "2025-09-01 07:34:13.255647: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 771072000 exceeds 10% of free system memory.\n",
      "/home/hyben/.conda/envs/MultiCW-finetune/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 406 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n",
      "\u001b[1;30;42mMultiCW overall:\u001b[0m\n",
      "Running classification:\n",
      "\u001b[1m577/577\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 339ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.86      0.87      9269\n",
      "           1       0.86      0.89      0.88      9175\n",
      "\n",
      "    accuracy                           0.88     18444\n",
      "   macro avg       0.88      0.88      0.88     18444\n",
      "weighted avg       0.88      0.88      0.88     18444\n",
      "\n",
      "Running classification:\n",
      "\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 341ms/step\n",
      "Done.\n",
      "\u001b[1;30;43mMultiCW Noisy Part:\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82      4744\n",
      "           1       0.81      0.84      0.82      4650\n",
      "\n",
      "    accuracy                           0.82      9394\n",
      "   macro avg       0.82      0.82      0.82      9394\n",
      "weighted avg       0.82      0.82      0.82      9394\n",
      "\n",
      "Running classification:\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 343ms/step\n",
      "Done.\n",
      "\u001b[1;30;43mMultiCW Structured Part:\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93      4525\n",
      "           1       0.92      0.95      0.93      4525\n",
      "\n",
      "    accuracy                           0.93      9050\n",
      "   macro avg       0.93      0.93      0.93      9050\n",
      "weighted avg       0.93      0.93      0.93      9050\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "detector = None\n",
    "models = ['xlm', 'mdb']\n",
    "\n",
    "for model in models:\n",
    "    if model == 'xlm':\n",
    "        print(f'{h_green}XLM-RoBERTa model:{h_stop}')\n",
    "        detector = XLMRobertaModel()\n",
    "    if model == 'mdb':\n",
    "        print(f'{h_green}mDBERTa model:{h_stop}')\n",
    "        detector = MDeBertaModel()\n",
    "\n",
    "    if not detector.load_model(model_name=f'{model}-multicw-2e6-5e'):\n",
    "        print(f'{h_yellow}No model found. Initiating fine-tuning:{h_stop}')\n",
    "        # Note: Works well with a small learning rate (e.g. 3e-6)\n",
    "        detector.train_model(multicw_train, multicw_dev, epochs=5, learn_rate=2e-6, lang='en', model_name=f'{model}-multicw')\n",
    "    \n",
    "    print(f'{h_yellow}MultiCW overall:{h_stop}')\n",
    "    _, report = detector.detect_claims(multicw_test)\n",
    "    print(report)\n",
    "    \n",
    "    test_noisy = multicw_test.loc[multicw_test['style']=='noisy']\n",
    "    _, report = detector.detect_claims(test_noisy, verbose=False)\n",
    "    print(f'{h_yellow}MultiCW Noisy Part:{h_stop}')\n",
    "    print(report)\n",
    "    \n",
    "    test_strut = multicw_test.loc[multicw_test['style']=='struct']\n",
    "    _, report = detector.detect_claims(test_strut, verbose=False)\n",
    "    print(f'{h_yellow}MultiCW Structured Part:{h_stop}')\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7a8aac-5718-4d9a-9edf-9bc3c6387364",
   "metadata": {},
   "source": [
    "### Evaluation of models on each language of the MultiCW dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98593984-c211-4661-863e-7f58bd37d258",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;42mXLM-RoBERTa model:\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-25 13:48:52.439519: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-09-25 13:48:52.484092: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-09-25 13:48:52.488673: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-09-25 13:48:52.493669: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-09-25 13:48:52.497508: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-09-25 13:48:52.500299: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-09-25 13:48:52.634365: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-09-25 13:48:52.635924: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-09-25 13:48:52.637426: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-09-25 13:48:52.638739: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4134 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2025-09-25 13:48:55.206177: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 768006144 exceeds 10% of free system memory.\n",
      "2025-09-25 13:48:57.595673: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 768006144 exceeds 10% of free system memory.\n",
      "/home/hyben/.conda/envs/MultiCW-finetune/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 401 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n",
      "\u001b[1;30;43mLanguage: sk:\u001b[0m\n",
      "Running classification:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1758800941.258255   15687 service.cc:145] XLA service 0x7fbda802de10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1758800941.258297   15687 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "2025-09-25 13:49:01.364506: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-25 13:49:01.617889: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1758800943.218445   15765 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_2670', 348 bytes spill stores, 356 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/38\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:39\u001b[0m 4s/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1758800944.139366   15687 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 197ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1758800953.799978   15826 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_85', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758800954.265829   15830 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_85', 264 bytes spill stores, 264 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758800954.300723   15826 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_85', 20 bytes spill stores, 20 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758800954.513391   15835 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_85', 1236 bytes spill stores, 1244 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758800954.526167   15832 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_2688', 36 bytes spill stores, 36 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758800954.531755   15834 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_85', 96 bytes spill stores, 96 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 313ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.94      0.89       596\n",
      "         1.0       0.93      0.83      0.88       596\n",
      "\n",
      "    accuracy                           0.89      1192\n",
      "   macro avg       0.89      0.89      0.88      1192\n",
      "weighted avg       0.89      0.89      0.88      1192\n",
      "\n",
      "\u001b[1;30;43mLanguage: pl:\u001b[0m\n",
      "Running classification:\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 198ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1758800965.717442   15957 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_2688', 32 bytes spill stores, 32 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 257ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.95      0.93       597\n",
      "         1.0       0.95      0.91      0.93       597\n",
      "\n",
      "    accuracy                           0.93      1194\n",
      "   macro avg       0.93      0.93      0.93      1194\n",
      "weighted avg       0.93      0.93      0.93      1194\n",
      "\n",
      "\u001b[1;30;43mLanguage: cs:\u001b[0m\n",
      "Running classification:\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 204ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.93      0.88       596\n",
      "         1.0       0.92      0.81      0.86       596\n",
      "\n",
      "    accuracy                           0.87      1192\n",
      "   macro avg       0.87      0.87      0.87      1192\n",
      "weighted avg       0.87      0.87      0.87      1192\n",
      "\n",
      "\u001b[1;30;43mLanguage: bg:\u001b[0m\n",
      "Running classification:\n",
      "\u001b[1m33/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 199ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1758800984.918218   16069 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_85', 20 bytes spill stores, 20 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758800985.246731   16069 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_85', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758800986.025997   16080 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_85', 96 bytes spill stores, 96 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758800986.058790   16067 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_2688', 36 bytes spill stores, 36 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758800986.078858   16081 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_85', 264 bytes spill stores, 264 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758800986.191317   16074 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_85', 1236 bytes spill stores, 1244 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 303ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.88      0.76       530\n",
      "         1.0       0.83      0.58      0.68       530\n",
      "\n",
      "    accuracy                           0.73      1060\n",
      "   macro avg       0.75      0.73      0.72      1060\n",
      "weighted avg       0.75      0.73      0.72      1060\n",
      "\n",
      "\u001b[1;30;43mLanguage: ru:\u001b[0m\n",
      "Running classification:\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 204ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.96      0.92       597\n",
      "         1.0       0.95      0.88      0.92       597\n",
      "\n",
      "    accuracy                           0.92      1194\n",
      "   macro avg       0.92      0.92      0.92      1194\n",
      "weighted avg       0.92      0.92      0.92      1194\n",
      "\n",
      "\u001b[1;30;43mLanguage: uk:\u001b[0m\n",
      "Running classification:\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 198ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1758801006.010361   16214 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_85', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758801006.272399   16220 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_85', 20 bytes spill stores, 20 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758801006.511710   16217 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_85', 96 bytes spill stores, 96 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758801007.103515   16218 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_85', 264 bytes spill stores, 264 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758801007.294484   16212 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_85', 1236 bytes spill stores, 1244 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758801007.476405   16211 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_2688', 36 bytes spill stores, 36 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 290ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.95      0.89       595\n",
      "         1.0       0.94      0.81      0.87       595\n",
      "\n",
      "    accuracy                           0.88      1190\n",
      "   macro avg       0.89      0.88      0.88      1190\n",
      "weighted avg       0.89      0.88      0.88      1190\n",
      "\n",
      "\u001b[1;30;43mLanguage: zh:\u001b[0m\n",
      "Running classification:\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 207ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.91      0.90       517\n",
      "         1.0       0.91      0.88      0.89       517\n",
      "\n",
      "    accuracy                           0.89      1034\n",
      "   macro avg       0.89      0.89      0.89      1034\n",
      "weighted avg       0.89      0.89      0.89      1034\n",
      "\n",
      "\u001b[1;30;43mLanguage: hi:\u001b[0m\n",
      "Running classification:\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 207ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.90      0.94       597\n",
      "         1.0       0.91      0.99      0.95       597\n",
      "\n",
      "    accuracy                           0.94      1194\n",
      "   macro avg       0.95      0.94      0.94      1194\n",
      "weighted avg       0.95      0.94      0.94      1194\n",
      "\n",
      "\u001b[1;30;43mLanguage: en:\u001b[0m\n",
      "Running classification:\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 268ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.81      0.78       600\n",
      "         1.0       0.79      0.72      0.75       600\n",
      "\n",
      "    accuracy                           0.77      1200\n",
      "   macro avg       0.77      0.77      0.77      1200\n",
      "weighted avg       0.77      0.77      0.77      1200\n",
      "\n",
      "\u001b[1;30;43mLanguage: ar:\u001b[0m\n",
      "Running classification:\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 200ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1758801048.131550   16463 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_2688', 40 bytes spill stores, 40 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 265ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.71      0.74       599\n",
      "         1.0       0.73      0.81      0.77       599\n",
      "\n",
      "    accuracy                           0.76      1198\n",
      "   macro avg       0.76      0.76      0.76      1198\n",
      "weighted avg       0.76      0.76      0.76      1198\n",
      "\n",
      "\u001b[1;30;43mLanguage: es:\u001b[0m\n",
      "Running classification:\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 207ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.90      0.84       599\n",
      "         1.0       0.88      0.76      0.82       599\n",
      "\n",
      "    accuracy                           0.83      1198\n",
      "   macro avg       0.84      0.83      0.83      1198\n",
      "weighted avg       0.84      0.83      0.83      1198\n",
      "\n",
      "\u001b[1;30;43mLanguage: fr:\u001b[0m\n",
      "Running classification:\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 206ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.94      0.97       597\n",
      "         1.0       0.94      0.99      0.97       597\n",
      "\n",
      "    accuracy                           0.97      1194\n",
      "   macro avg       0.97      0.97      0.97      1194\n",
      "weighted avg       0.97      0.97      0.97      1194\n",
      "\n",
      "\u001b[1;30;43mLanguage: tr:\u001b[0m\n",
      "Running classification:\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 214ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.73      0.77       592\n",
      "         1.0       0.76      0.83      0.79       592\n",
      "\n",
      "    accuracy                           0.78      1184\n",
      "   macro avg       0.78      0.78      0.78      1184\n",
      "weighted avg       0.78      0.78      0.78      1184\n",
      "\n",
      "\u001b[1;30;43mLanguage: bn:\u001b[0m\n",
      "Running classification:\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 201ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1758801084.442761   16664 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_85', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758801084.749400   16660 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_85', 20 bytes spill stores, 20 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758801084.839474   16667 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_85', 96 bytes spill stores, 96 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758801085.394506   16658 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_85', 264 bytes spill stores, 264 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758801085.717647   16666 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_85', 1236 bytes spill stores, 1244 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758801085.857980   16663 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_2688', 28 bytes spill stores, 28 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 311ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.83      0.90       465\n",
      "         1.0       0.85      0.99      0.92       465\n",
      "\n",
      "    accuracy                           0.91       930\n",
      "   macro avg       0.92      0.91      0.91       930\n",
      "weighted avg       0.92      0.91      0.91       930\n",
      "\n",
      "\u001b[1;30;43mLanguage: pt:\u001b[0m\n",
      "Running classification:\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 208ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.96      0.98       597\n",
      "         1.0       0.96      0.99      0.98       597\n",
      "\n",
      "    accuracy                           0.98      1194\n",
      "   macro avg       0.98      0.98      0.98      1194\n",
      "weighted avg       0.98      0.98      0.98      1194\n",
      "\n",
      "\u001b[1;30;43mLanguage: de:\u001b[0m\n",
      "Running classification:\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 209ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.93      0.96       596\n",
      "         1.0       0.94      0.99      0.96       596\n",
      "\n",
      "    accuracy                           0.96      1192\n",
      "   macro avg       0.96      0.96      0.96      1192\n",
      "weighted avg       0.96      0.96      0.96      1192\n",
      "\n",
      "\u001b[1;30;42mmDBERTa model:\u001b[0m\n",
      "Loading full model from: Models/mdb-multicw-2e6-5e.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyben/.conda/envs/MultiCW-finetune/lib/python3.10/site-packages/keras/src/saving/serialization_lib.py:734: UserWarning: `compile()` was not called as part of model loading because the model's `compile()` method is custom. All subclassed Models that have `compile()` overridden should also override `get_compile_config()` and `compile_from_config(config)`. Alternatively, you can call `compile()` manually after loading.\n",
      "  instance.compile_from_config(compile_config)\n",
      "2025-09-25 13:52:08.348909: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 771072000 exceeds 10% of free system memory.\n",
      "/home/hyben/.conda/envs/MultiCW-finetune/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 406 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n",
      "\u001b[1;30;43mLanguage: sk:\u001b[0m\n",
      "Running classification:\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 334ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1758801152.960748   16917 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_133', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758801153.223695   16920 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_135', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758801153.349519   16922 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_133', 96 bytes spill stores, 96 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758801153.484898   16924 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_133', 268 bytes spill stores, 268 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758801154.225518   16916 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_135', 96 bytes spill stores, 96 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758801154.235906   16917 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_135', 268 bytes spill stores, 268 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758801154.402099   16915 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_133', 1300 bytes spill stores, 1324 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758801155.572088   16915 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_135', 1300 bytes spill stores, 1324 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 523ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.93      0.91       596\n",
      "         1.0       0.93      0.88      0.90       596\n",
      "\n",
      "    accuracy                           0.91      1192\n",
      "   macro avg       0.91      0.91      0.91      1192\n",
      "weighted avg       0.91      0.91      0.91      1192\n",
      "\n",
      "\u001b[1;30;43mLanguage: pl:\u001b[0m\n",
      "Running classification:\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 395ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.95      0.95       597\n",
      "         1.0       0.95      0.95      0.95       597\n",
      "\n",
      "    accuracy                           0.95      1194\n",
      "   macro avg       0.95      0.95      0.95      1194\n",
      "weighted avg       0.95      0.95      0.95      1194\n",
      "\n",
      "\u001b[1;30;43mLanguage: cs:\u001b[0m\n",
      "Running classification:\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 335ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.93      0.89       596\n",
      "         1.0       0.93      0.84      0.88       596\n",
      "\n",
      "    accuracy                           0.89      1192\n",
      "   macro avg       0.89      0.89      0.89      1192\n",
      "weighted avg       0.89      0.89      0.89      1192\n",
      "\n",
      "\u001b[1;30;43mLanguage: bg:\u001b[0m\n",
      "Running classification:\n",
      "\u001b[1m33/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 337ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1758801198.637774   17172 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_135', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758801198.816680   17170 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_135', 96 bytes spill stores, 96 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758801199.431293   17159 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_135', 268 bytes spill stores, 268 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758801199.703457   17166 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_135', 1300 bytes spill stores, 1324 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758801199.967085   17158 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_133', 96 bytes spill stores, 96 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758801200.318643   17169 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_133', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758801200.542347   17162 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_133', 1300 bytes spill stores, 1324 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758801200.581644   17168 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_133', 268 bytes spill stores, 268 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 477ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.93      0.81       530\n",
      "         1.0       0.90      0.62      0.73       530\n",
      "\n",
      "    accuracy                           0.77      1060\n",
      "   macro avg       0.80      0.77      0.77      1060\n",
      "weighted avg       0.80      0.77      0.77      1060\n",
      "\n",
      "\u001b[1;30;43mLanguage: ru:\u001b[0m\n",
      "Running classification:\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 334ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.96      0.93       597\n",
      "         1.0       0.95      0.90      0.93       597\n",
      "\n",
      "    accuracy                           0.93      1194\n",
      "   macro avg       0.93      0.93      0.93      1194\n",
      "weighted avg       0.93      0.93      0.93      1194\n",
      "\n",
      "\u001b[1;30;43mLanguage: uk:\u001b[0m\n",
      "Running classification:\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 341ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1758801230.747434   17313 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_135', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758801231.445656   17318 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_133', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758801231.643947   17313 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_135', 96 bytes spill stores, 96 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758801232.098224   17328 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_135', 268 bytes spill stores, 268 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758801232.357707   17317 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_133', 96 bytes spill stores, 96 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758801232.671572   17325 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_135', 1300 bytes spill stores, 1324 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758801232.765834   17315 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_133', 1300 bytes spill stores, 1324 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758801232.929352   17317 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_133', 268 bytes spill stores, 268 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 468ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.95      0.90       595\n",
      "         1.0       0.94      0.85      0.89       595\n",
      "\n",
      "    accuracy                           0.90      1190\n",
      "   macro avg       0.90      0.90      0.90      1190\n",
      "weighted avg       0.90      0.90      0.90      1190\n",
      "\n",
      "\u001b[1;30;43mLanguage: zh:\u001b[0m\n",
      "Running classification:\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 340ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.91      0.89       517\n",
      "         1.0       0.90      0.87      0.89       517\n",
      "\n",
      "    accuracy                           0.89      1034\n",
      "   macro avg       0.89      0.89      0.89      1034\n",
      "weighted avg       0.89      0.89      0.89      1034\n",
      "\n",
      "\u001b[1;30;43mLanguage: hi:\u001b[0m\n",
      "Running classification:\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 344ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.84      0.91       597\n",
      "         1.0       0.86      1.00      0.93       597\n",
      "\n",
      "    accuracy                           0.92      1194\n",
      "   macro avg       0.93      0.92      0.92      1194\n",
      "weighted avg       0.93      0.92      0.92      1194\n",
      "\n",
      "\u001b[1;30;43mLanguage: en:\u001b[0m\n",
      "Running classification:\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 417ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.80      0.78       600\n",
      "         1.0       0.79      0.73      0.76       600\n",
      "\n",
      "    accuracy                           0.77      1200\n",
      "   macro avg       0.77      0.77      0.77      1200\n",
      "weighted avg       0.77      0.77      0.77      1200\n",
      "\n",
      "\u001b[1;30;43mLanguage: ar:\u001b[0m\n",
      "Running classification:\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 413ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.56      0.66       599\n",
      "         1.0       0.66      0.86      0.75       599\n",
      "\n",
      "    accuracy                           0.71      1198\n",
      "   macro avg       0.73      0.71      0.70      1198\n",
      "weighted avg       0.73      0.71      0.70      1198\n",
      "\n",
      "\u001b[1;30;43mLanguage: es:\u001b[0m\n",
      "Running classification:\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 354ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.90      0.83       599\n",
      "         1.0       0.88      0.72      0.79       599\n",
      "\n",
      "    accuracy                           0.81      1198\n",
      "   macro avg       0.82      0.81      0.81      1198\n",
      "weighted avg       0.82      0.81      0.81      1198\n",
      "\n",
      "\u001b[1;30;43mLanguage: fr:\u001b[0m\n",
      "Running classification:\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 355ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.93      0.96       597\n",
      "         1.0       0.93      1.00      0.96       597\n",
      "\n",
      "    accuracy                           0.96      1194\n",
      "   macro avg       0.96      0.96      0.96      1194\n",
      "weighted avg       0.96      0.96      0.96      1194\n",
      "\n",
      "\u001b[1;30;43mLanguage: tr:\u001b[0m\n",
      "Running classification:\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 361ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.60      0.72       592\n",
      "         1.0       0.70      0.91      0.79       592\n",
      "\n",
      "    accuracy                           0.76      1184\n",
      "   macro avg       0.79      0.76      0.75      1184\n",
      "weighted avg       0.79      0.76      0.75      1184\n",
      "\n",
      "\u001b[1;30;43mLanguage: bn:\u001b[0m\n",
      "Running classification:\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 354ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1758801345.566506   17766 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_168', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758801345.900553   17775 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_168', 96 bytes spill stores, 96 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758801346.042456   17770 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_168', 264 bytes spill stores, 264 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758801346.485220   17771 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_169', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758801346.621448   17773 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_168', 1304 bytes spill stores, 1328 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758801347.567662   17764 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_169', 96 bytes spill stores, 96 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758801347.963996   17769 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_169', 264 bytes spill stores, 264 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758801348.177054   17766 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_169', 1304 bytes spill stores, 1328 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 537ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.84      0.91       465\n",
      "         1.0       0.86      1.00      0.92       465\n",
      "\n",
      "    accuracy                           0.92       930\n",
      "   macro avg       0.93      0.92      0.92       930\n",
      "weighted avg       0.93      0.92      0.92       930\n",
      "\n",
      "\u001b[1;30;43mLanguage: pt:\u001b[0m\n",
      "Running classification:\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 348ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.96      0.98       597\n",
      "         1.0       0.96      0.99      0.98       597\n",
      "\n",
      "    accuracy                           0.98      1194\n",
      "   macro avg       0.98      0.98      0.98      1194\n",
      "weighted avg       0.98      0.98      0.98      1194\n",
      "\n",
      "\u001b[1;30;43mLanguage: de:\u001b[0m\n",
      "Running classification:\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 357ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.94      0.97       596\n",
      "         1.0       0.95      1.00      0.97       596\n",
      "\n",
      "    accuracy                           0.97      1192\n",
      "   macro avg       0.97      0.97      0.97      1192\n",
      "weighted avg       0.97      0.97      0.97      1192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "detector = None\n",
    "models = ['xlm', 'mdb']\n",
    "\n",
    "for model in models:\n",
    "    if model == 'xlm':\n",
    "        print(f'{h_green}XLM-RoBERTa model:{h_stop}')\n",
    "        detector = XLMRobertaModel()\n",
    "    if model == 'mdb':\n",
    "        print(f'{h_green}mDBERTa model:{h_stop}')\n",
    "        detector = MDeBertaModel()\n",
    "\n",
    "    if not detector.load_model(model_name=f'{model}-multicw-2e6-5e'):\n",
    "        print(f'{h_yellow}No model found. Initiating fine-tuning:{h_stop}')\n",
    "        # Note: Works well with a small learning rate (e.g. 3e-6)\n",
    "        detector.train_model(multicw_train, multicw_dev, epochs=5, learn_rate=2e-6, lang='en', model_name=f'{model}-multicw')\n",
    "\n",
    "    languages = multicw_test['lang'].unique()\n",
    "\n",
    "    for lang in languages:\n",
    "        print(f'{h_yellow}Language: {lang}:{h_stop}')\n",
    "        _, report = detector.detect_claims(multicw_test[multicw_test['lang'] == lang])\n",
    "        print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f43847a8ba1952a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Out-domain evaluation\n",
    "- Evaluation of the fine-tuned models on 4 more languages obtained from source datasets.\n",
    "\n",
    "#### XLM-RoBERTa model:\n",
    "<table>\n",
    "<tr>\n",
    "<td>\n",
    "\n",
    "| Class            | Precision | Recall | F1-score | Support   |\n",
    "| ---------------- | --------- | ------ | -------- | --------- |\n",
    "| 0                | 0.94      | 0.75   | 0.84     | 16000     |\n",
    "| 1                | 0.76      | 0.95   | 0.85     | 13647     |\n",
    "| **Accuracy**     |           |        | **0.84** | **29647** |\n",
    "| **Macro avg**    | 0.85      | 0.85   | 0.84     | 29647     |\n",
    "| **Weighted avg** | 0.86      | 0.84   | 0.84     | 29647     |\n",
    "                    MultiCW Overall.\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "| Class            | Precision | Recall | F1-score | Support  |\n",
    "| ---------------- | --------- | ------ | -------- | -------- |\n",
    "| 0                | 0.91      | 0.70   | 0.79     | 8000     |\n",
    "| 1                | 0.76      | 0.93   | 0.84     | 8000     |\n",
    "| **Accuracy**     |           |        | **0.82** | **16000** |\n",
    "| **Macro avg**    | 0.83      | 0.82   | 0.81     | 16000     |\n",
    "| **Weighted avg** | 0.83      | 0.82   | 0.81     | 16000     |\n",
    "                MultiCW Noisy Part.\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "| Class            | Precision | Recall | F1-score | Support  |\n",
    "| ---------------- | --------- | ------ | -------- | -------- |\n",
    "| 0                | 0.97      | 0.80   | 0.88     | 8000     |\n",
    "| 1                | 0.78      | 0.97   | 0.86     | 5647     |\n",
    "| **Accuracy**     |           |        | **0.87** | **13647** |\n",
    "| **Macro avg**    | 0.87      | 0.88   | 0.87     | 13647     |\n",
    "| **Weighted avg** | 0.89      | 0.87   | 0.87     | 13647     |\n",
    "                MultiCW Structured Part.\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "#### mDBERTa model:\n",
    "<table>\n",
    "<tr>\n",
    "<td>\n",
    "\n",
    "| Class            | Precision | Recall | F1-score | Support   |\n",
    "| ---------------- | --------- | ------ | -------- | --------- |\n",
    "| 0                | 0.97      | 0.74   | 0.84     | 16000     |\n",
    "| 1                | 0.76      | 0.97   | 0.85     | 13647     |\n",
    "| **Accuracy**     |           |        | **0.85** | **29647** |\n",
    "| **Macro avg**    | 0.86      | 0.86   | 0.85     | 29647     |\n",
    "| **Weighted avg** | 0.87      | 0.85   | 0.85     | 29647     |\n",
    "                    MultiCW Overall.\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "| Class            | Precision | Recall | F1-score | Support  |\n",
    "| ---------------- | --------- | ------ | -------- | -------- |\n",
    "| 0                | 0.95      | 0.68   | 0.80     | 8000     |\n",
    "| 1                | 0.75      | 0.96   | 0.85     | 8000     |\n",
    "| **Accuracy**     |           |        | **0.82** | **16000** |\n",
    "| **Macro avg**    | 0.85      | 0.82   | 0.82     | 16000     |\n",
    "| **Weighted avg** | 0.85      | 0.82   | 0.82     | 16000     |\n",
    "                MultiCW Noisy Part.\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "| Class            | Precision | Recall | F1-score | Support  |\n",
    "| ---------------- | --------- | ------ | -------- | -------- |\n",
    "| 0                | 0.98      | 0.79   | 0.88     | 8000     |\n",
    "| 1                | 0.77      | 0.98   | 0.86     | 5647     |\n",
    "| **Accuracy**     |           |        | **0.87** | **13647** |\n",
    "| **Macro avg**    | 0.88      | 0.89   | 0.87     | 13647     |\n",
    "| **Weighted avg** | 0.90      | 0.87   | 0.87     | 13647     |\n",
    "                MultiCW Structured Part.\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2e6f104-4696-4390-9d44-b9e40b88c988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;42mXLM-RoBERTa model:\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-01 13:46:26.855076: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-10-01 13:46:26.980819: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-10-01 13:46:26.983829: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-10-01 13:46:26.987615: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-10-01 13:46:26.990568: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-10-01 13:46:26.993170: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-10-01 13:46:27.128533: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-10-01 13:46:27.130797: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-10-01 13:46:27.132902: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-10-01 13:46:27.135149: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4174 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2025-10-01 13:46:29.675567: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 768006144 exceeds 10% of free system memory.\n",
      "2025-10-01 13:46:31.637086: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 768006144 exceeds 10% of free system memory.\n",
      "/home/hyben/.conda/envs/MultiCW-finetune/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 401 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n",
      "\u001b[1;30;43mMultiCW overall:\u001b[0m\n",
      "Running classification:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1759319194.657170   23559 service.cc:145] XLA service 0x7f7b980022e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1759319194.657218   23559 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "2025-10-01 13:46:34.729265: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-10-01 13:46:34.936323: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1759319196.303246   23640 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_2670', 348 bytes spill stores, 356 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/868\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m53:01\u001b[0m 4s/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1759319197.122821   23559 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m867/868\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 195ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1759319368.411070   23738 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_2688', 60 bytes spill stores, 60 bytes spill loads\n",
      "\n",
      "I0000 00:00:1759319368.750441   23745 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_2688', 372 bytes spill stores, 380 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m868/868\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 199ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.78      0.86     15997\n",
      "           1       0.76      0.94      0.84     11764\n",
      "\n",
      "    accuracy                           0.85     27761\n",
      "   macro avg       0.86      0.86      0.85     27761\n",
      "weighted avg       0.87      0.85      0.85     27761\n",
      "\n",
      "\u001b[1;30;43mMultiCW Noisy Part:\u001b[0m\n",
      "Running classification:\n",
      "\u001b[1m441/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 198ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1759319459.614995   23850 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_85', 20 bytes spill stores, 20 bytes spill loads\n",
      "\n",
      "I0000 00:00:1759319459.942354   23852 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_2688', 28 bytes spill stores, 28 bytes spill loads\n",
      "\n",
      "I0000 00:00:1759319459.960196   23863 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_85', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "I0000 00:00:1759319460.020364   23853 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_85', 96 bytes spill stores, 96 bytes spill loads\n",
      "\n",
      "I0000 00:00:1759319460.285923   23857 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_85', 264 bytes spill stores, 264 bytes spill loads\n",
      "\n",
      "I0000 00:00:1759319460.430930   23860 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_85', 1236 bytes spill stores, 1244 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 205ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.76      0.84      7997\n",
      "           1       0.75      0.92      0.83      6117\n",
      "\n",
      "    accuracy                           0.83     14114\n",
      "   macro avg       0.84      0.84      0.83     14114\n",
      "weighted avg       0.85      0.83      0.83     14114\n",
      "\n",
      "\u001b[1;30;43mMultiCW Structured Part:\u001b[0m\n",
      "Running classification:\n",
      "\u001b[1m426/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 200ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1759319549.625594   24073 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_2688', 40 bytes spill stores, 40 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 205ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.80      0.88      8000\n",
      "           1       0.78      0.97      0.86      5647\n",
      "\n",
      "    accuracy                           0.87     13647\n",
      "   macro avg       0.87      0.88      0.87     13647\n",
      "weighted avg       0.89      0.87      0.87     13647\n",
      "\n",
      "\u001b[1;30;42mmDBERTa model:\u001b[0m\n",
      "Loading full model from: Models/mdb-multicw-2e6-5e.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyben/.conda/envs/MultiCW-finetune/lib/python3.10/site-packages/keras/src/saving/serialization_lib.py:734: UserWarning: `compile()` was not called as part of model loading because the model's `compile()` method is custom. All subclassed Models that have `compile()` overridden should also override `get_compile_config()` and `compile_from_config(config)`. Alternatively, you can call `compile()` manually after loading.\n",
      "  instance.compile_from_config(compile_config)\n",
      "2025-10-01 13:52:49.381804: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 771072000 exceeds 10% of free system memory.\n",
      "/home/hyben/.conda/envs/MultiCW-finetune/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 406 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n",
      "\u001b[1;30;43mMultiCW overall:\u001b[0m\n",
      "Running classification:\n",
      "\u001b[1m868/868\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 345ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.79      0.87     15997\n",
      "           1       0.77      0.97      0.86     11764\n",
      "\n",
      "    accuracy                           0.86     27761\n",
      "   macro avg       0.87      0.88      0.86     27761\n",
      "weighted avg       0.89      0.86      0.86     27761\n",
      "\n",
      "\u001b[1;30;43mMultiCW Noisy Part:\u001b[0m\n",
      "Running classification:\n",
      "\u001b[1m441/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 350ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1759320032.972179   25679 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_169', 1304 bytes spill stores, 1328 bytes spill loads\n",
      "\n",
      "I0000 00:00:1759320033.061594   25693 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_169', 96 bytes spill stores, 96 bytes spill loads\n",
      "\n",
      "I0000 00:00:1759320033.109274   25682 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_169', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1759320033.264362   25688 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_168', 96 bytes spill stores, 96 bytes spill loads\n",
      "\n",
      "I0000 00:00:1759320033.363912   25681 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_169', 264 bytes spill stores, 264 bytes spill loads\n",
      "\n",
      "I0000 00:00:1759320033.608206   25680 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_168', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1759320033.813880   25686 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_168', 264 bytes spill stores, 264 bytes spill loads\n",
      "\n",
      "I0000 00:00:1759320034.111190   25682 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_168', 1304 bytes spill stores, 1328 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 360ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.78      0.86      7997\n",
      "           1       0.77      0.96      0.85      6117\n",
      "\n",
      "    accuracy                           0.86     14114\n",
      "   macro avg       0.86      0.87      0.86     14114\n",
      "weighted avg       0.88      0.86      0.86     14114\n",
      "\n",
      "\u001b[1;30;43mMultiCW Structured Part:\u001b[0m\n",
      "Running classification:\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 354ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.79      0.88      8000\n",
      "           1       0.77      0.98      0.86      5647\n",
      "\n",
      "    accuracy                           0.87     13647\n",
      "   macro avg       0.88      0.89      0.87     13647\n",
      "weighted avg       0.90      0.87      0.87     13647\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "detector = None\n",
    "models = ['xlm', 'mdb']\n",
    "\n",
    "for model in models:\n",
    "    if model == 'xlm':\n",
    "        print(f'{h_green}XLM-RoBERTa model:{h_stop}')\n",
    "        detector = XLMRobertaModel()\n",
    "    if model == 'mdb':\n",
    "        print(f'{h_green}mDBERTa model:{h_stop}')\n",
    "        detector = MDeBertaModel()\n",
    "\n",
    "    if not detector.load_model(model_name=f'{model}-multicw-2e6-5e'):\n",
    "        print(f'{h_yellow}No model found. Initiating fine-tuning:{h_stop}')\n",
    "        # Note: Works well with a small learning rate (e.g. 3e-6)\n",
    "        detector.train_model(multicw_train, multicw_dev, epochs=5, learn_rate=2e-6, lang='en', model_name=f'{model}-multicw')\n",
    "    \n",
    "    print(f'{h_yellow}MultiCW overall:{h_stop}')\n",
    "    _, report = detector.detect_claims(multicw_ood)\n",
    "    print(report)\n",
    "    \n",
    "    test_noisy = multicw_ood.loc[multicw_ood['style']=='noisy']\n",
    "    print(f'{h_yellow}MultiCW Noisy Part:{h_stop}')\n",
    "    _, report = detector.detect_claims(test_noisy, verbose=False)\n",
    "    print(report)\n",
    "    \n",
    "    test_strut = multicw_ood.loc[multicw_ood['style']=='struc']\n",
    "    print(f'{h_yellow}MultiCW Structured Part:{h_stop}')\n",
    "    _, report = detector.detect_claims(test_strut, verbose=False)\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0618310c-377d-46d4-8619-75201f6efd90",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Evaluation of models on each language of the Out-of-distribution dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51990ac8-3f2a-4cdb-9fa5-5912d52f4c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;42mXLM-RoBERTa model:\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-25 19:50:35.876046: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-09-25 19:50:35.937876: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-09-25 19:50:35.940863: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-09-25 19:50:35.944616: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-09-25 19:50:35.947856: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-09-25 19:50:35.950599: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-09-25 19:50:36.094469: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-09-25 19:50:36.096532: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-09-25 19:50:36.098326: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-09-25 19:50:36.100377: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4134 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2025-09-25 19:50:38.372184: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 768006144 exceeds 10% of free system memory.\n",
      "2025-09-25 19:50:40.385238: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 768006144 exceeds 10% of free system memory.\n",
      "/home/hyben/.conda/envs/MultiCW-finetune/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 401 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n",
      "\u001b[1;30;43mLanguage: nl:\u001b[0m\n",
      "Running classification:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1758822643.508835   28888 service.cc:145] XLA service 0x7f791402d3e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1758822643.508880   28888 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "2025-09-25 19:50:43.584956: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-25 19:50:43.783665: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1758822645.081311   28970 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_2670', 348 bytes spill stores, 356 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/226\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13:30\u001b[0m 4s/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1758822645.910936   28888 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 193ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1758822691.313673   29036 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_2688', 60 bytes spill stores, 60 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758822691.746573   29030 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_2688', 348 bytes spill stores, 348 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 208ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.73      0.80      4000\n",
      "           1       0.72      0.88      0.79      3227\n",
      "\n",
      "    accuracy                           0.79      7227\n",
      "   macro avg       0.80      0.80      0.79      7227\n",
      "weighted avg       0.81      0.79      0.79      7227\n",
      "\n",
      "\u001b[1;30;43mLanguage: my:\u001b[0m\n",
      "Running classification:\n",
      "\u001b[1m228/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 195ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1758822739.014394   29121 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_99', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758822739.224198   29131 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_99', 20 bytes spill stores, 20 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758822739.319101   29120 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_99', 96 bytes spill stores, 96 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758822739.358021   29127 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_72', 152 bytes spill stores, 152 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758822739.412789   29125 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_99', 264 bytes spill stores, 264 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758822739.611391   29119 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_72', 160 bytes spill stores, 156 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758822740.017120   29132 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_99', 1236 bytes spill stores, 1244 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 208ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.52      0.69      4000\n",
      "           1       0.63      1.00      0.77      3297\n",
      "\n",
      "    accuracy                           0.74      7297\n",
      "   macro avg       0.81      0.76      0.73      7297\n",
      "weighted avg       0.83      0.74      0.73      7297\n",
      "\n",
      "\u001b[1;30;43mLanguage: it:\u001b[0m\n",
      "Running classification:\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 197ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.89      0.93      4000\n",
      "           1       0.90      0.97      0.94      4000\n",
      "\n",
      "    accuracy                           0.93      8000\n",
      "   macro avg       0.94      0.93      0.93      8000\n",
      "weighted avg       0.94      0.93      0.93      8000\n",
      "\n",
      "\u001b[1;30;43mLanguage: mk:\u001b[0m\n",
      "Running classification:\n",
      "\u001b[1m222/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 197ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1758822838.187683   29300 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_2688', 60 bytes spill stores, 60 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758822838.596902   29315 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_2688', 372 bytes spill stores, 380 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 208ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.86      0.90      4000\n",
      "           1       0.84      0.93      0.88      3123\n",
      "\n",
      "    accuracy                           0.89      7123\n",
      "   macro avg       0.89      0.89      0.89      7123\n",
      "weighted avg       0.89      0.89      0.89      7123\n",
      "\n",
      "\u001b[1;30;42mmDBERTa model:\u001b[0m\n",
      "Loading full model from: Models/mdb-multicw-2e6-5e.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyben/.conda/envs/MultiCW-finetune/lib/python3.10/site-packages/keras/src/saving/serialization_lib.py:734: UserWarning: `compile()` was not called as part of model loading because the model's `compile()` method is custom. All subclassed Models that have `compile()` overridden should also override `get_compile_config()` and `compile_from_config(config)`. Alternatively, you can call `compile()` manually after loading.\n",
      "  instance.compile_from_config(compile_config)\n",
      "2025-09-25 19:54:16.975197: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 771072000 exceeds 10% of free system memory.\n",
      "/home/hyben/.conda/envs/MultiCW-finetune/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 406 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n",
      "\u001b[1;30;43mLanguage: nl:\u001b[0m\n",
      "Running classification:\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 347ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.67      0.78      4000\n",
      "           1       0.69      0.94      0.80      3227\n",
      "\n",
      "    accuracy                           0.79      7227\n",
      "   macro avg       0.81      0.80      0.79      7227\n",
      "weighted avg       0.82      0.79      0.79      7227\n",
      "\n",
      "\u001b[1;30;43mLanguage: my:\u001b[0m\n",
      "Running classification:\n",
      "\u001b[1m228/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 332ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1758823019.472424   29538 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_183', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758823019.755811   29530 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_183', 264 bytes spill stores, 264 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758823019.917077   29539 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_182', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758823020.144542   29524 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_183', 96 bytes spill stores, 96 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758823020.414441   29536 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_183', 1304 bytes spill stores, 1328 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758823020.750920   29525 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_98', 152 bytes spill stores, 152 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758823021.257550   29530 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_98', 160 bytes spill stores, 156 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758823021.426644   29533 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_182', 264 bytes spill stores, 264 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758823021.868879   29524 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_182', 96 bytes spill stores, 96 bytes spill loads\n",
      "\n",
      "I0000 00:00:1758823022.040964   29529 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_182', 1304 bytes spill stores, 1328 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 353ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.55      0.71      4000\n",
      "           1       0.65      1.00      0.78      3297\n",
      "\n",
      "    accuracy                           0.75      7297\n",
      "   macro avg       0.82      0.77      0.75      7297\n",
      "weighted avg       0.84      0.75      0.74      7297\n",
      "\n",
      "\u001b[1;30;43mLanguage: it:\u001b[0m\n",
      "Running classification:\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 334ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.90      0.94      4000\n",
      "           1       0.90      0.98      0.94      4000\n",
      "\n",
      "    accuracy                           0.94      8000\n",
      "   macro avg       0.94      0.94      0.94      8000\n",
      "weighted avg       0.94      0.94      0.94      8000\n",
      "\n",
      "\u001b[1;30;43mLanguage: mk:\u001b[0m\n",
      "Running classification:\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 343ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.84      0.90      4000\n",
      "           1       0.83      0.97      0.89      3123\n",
      "\n",
      "    accuracy                           0.90      7123\n",
      "   macro avg       0.90      0.91      0.90      7123\n",
      "weighted avg       0.91      0.90      0.90      7123\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "detector = None\n",
    "models = ['xlm', 'mdb']\n",
    "\n",
    "for model in models:\n",
    "    if model == 'xlm':\n",
    "        print(f'{h_green}XLM-RoBERTa model:{h_stop}')\n",
    "        detector = XLMRobertaModel()\n",
    "    if model == 'mdb':\n",
    "        print(f'{h_green}mDBERTa model:{h_stop}')\n",
    "        detector = MDeBertaModel()\n",
    "\n",
    "    if not detector.load_model(model_name=f'{model}-multicw-2e6-5e'):\n",
    "        print(f'{h_yellow}No model found. Initiating fine-tuning:{h_stop}')\n",
    "        # Note: Works well with a small learning rate (e.g. 3e-6)\n",
    "        detector.train_model(multicw_train, multicw_dev, epochs=5, learn_rate=2e-6, lang='en', model_name=f'{model}-multicw')\n",
    "\n",
    "    languages = multicw_ood['lang'].unique()\n",
    "\n",
    "    for lang in languages:\n",
    "        print(f'{h_yellow}Language: {lang}:{h_stop}')\n",
    "        _, report = detector.detect_claims(multicw_ood[multicw_ood['lang'] == lang])\n",
    "        print(report)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "modelId": 2834,
     "modelInstanceId": 4721,
     "sourceId": 6189,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 2820,
     "modelInstanceId": 4688,
     "sourceId": 6067,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "MultiCW-finetune",
   "language": "python",
   "name": "multicw-finetune"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0abbc91f30b04bd3b464ab626caa4ef6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2511f785d020410e851c8f198278c7da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DropdownModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DropdownModel",
      "_options_labels": [
       "cpu",
       "gpu"
      ],
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "DropdownView",
      "description": "Storage mode:",
      "description_tooltip": null,
      "disabled": false,
      "index": 1,
      "layout": "IPY_MODEL_8af9da3904434c8db72bf48038475c9e",
      "style": "IPY_MODEL_0abbc91f30b04bd3b464ab626caa4ef6"
     }
    },
    "2c2931510812437899b50874520958b0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "353fd4c3ba06412d9431ead32ef52b9c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "IntSliderModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntSliderModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "IntSliderView",
      "continuous_update": true,
      "description": "Batch size:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_8642bd2f2a174d2eafd1ae06aaa494e5",
      "max": 32,
      "min": 1,
      "orientation": "horizontal",
      "readout": true,
      "readout_format": "d",
      "step": 1,
      "style": "IPY_MODEL_6305e85181ee4afa84499a116c911b1c",
      "value": 8
     }
    },
    "5b36326a73a84c80aadbe97684b4083c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bfac425cbea74dbca85bc28aec8fca84",
       "IPY_MODEL_353fd4c3ba06412d9431ead32ef52b9c",
       "IPY_MODEL_e2a27094e6ab478e887d6dbd0d166255",
       "IPY_MODEL_c498aabcc4754ea69cc7939e23b295f2",
       "IPY_MODEL_f0a443c22c71401cadcd0ed9d720a50b",
       "IPY_MODEL_2511f785d020410e851c8f198278c7da"
      ],
      "layout": "IPY_MODEL_f151a00a84a444a2ac3dde95d6449f76"
     }
    },
    "6305e85181ee4afa84499a116c911b1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "SliderStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "SliderStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": "",
      "handle_color": null
     }
    },
    "6d2245fa0357414793ec484e42a407ce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "702fc0ae0e9646e195974358ada8698e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "SliderStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "SliderStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": "",
      "handle_color": null
     }
    },
    "8642bd2f2a174d2eafd1ae06aaa494e5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8988b2e3116348faae276ec36bf6b2af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8af9da3904434c8db72bf48038475c9e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bfac425cbea74dbca85bc28aec8fca84": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DropdownModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DropdownModel",
      "_options_labels": [
       "mDeBERTa",
       "XLM-RoBERTa",
       "LESA"
      ],
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "DropdownView",
      "description": "Model:",
      "description_tooltip": null,
      "disabled": false,
      "index": 0,
      "layout": "IPY_MODEL_ecacd507e05b492dbdcfd924c6c7e039",
      "style": "IPY_MODEL_8988b2e3116348faae276ec36bf6b2af"
     }
    },
    "c1fa2f69f0a147e891184b3d41decae5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "SliderStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "SliderStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": "",
      "handle_color": null
     }
    },
    "c498aabcc4754ea69cc7939e23b295f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatLogSliderModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatLogSliderModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "FloatLogSliderView",
      "base": 10,
      "continuous_update": true,
      "description": "Learning Rate:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_6d2245fa0357414793ec484e42a407ce",
      "max": -1,
      "min": -10,
      "orientation": "horizontal",
      "readout": true,
      "readout_format": ".1e",
      "step": 0.1,
      "style": "IPY_MODEL_cf376d4917444367af900a2ea6fbfbd1",
      "value": 3e-05
     }
    },
    "cf376d4917444367af900a2ea6fbfbd1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "SliderStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "SliderStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": "initial",
      "handle_color": null
     }
    },
    "e2a27094e6ab478e887d6dbd0d166255": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "IntSliderModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntSliderModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "IntSliderView",
      "continuous_update": true,
      "description": "Batch chunk size:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_fb777cd857e848febd846dabb6f351e4",
      "max": 32,
      "min": 1,
      "orientation": "horizontal",
      "readout": true,
      "readout_format": "d",
      "step": 1,
      "style": "IPY_MODEL_c1fa2f69f0a147e891184b3d41decae5",
      "value": 8
     }
    },
    "ecacd507e05b492dbdcfd924c6c7e039": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f0a443c22c71401cadcd0ed9d720a50b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatSliderModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatSliderModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "FloatSliderView",
      "continuous_update": true,
      "description": "Classifier threshold:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_2c2931510812437899b50874520958b0",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "readout": true,
      "readout_format": ".2f",
      "step": 1e-05,
      "style": "IPY_MODEL_702fc0ae0e9646e195974358ada8698e",
      "value": 0.5
     }
    },
    "f151a00a84a444a2ac3dde95d6449f76": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb777cd857e848febd846dabb6f351e4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
