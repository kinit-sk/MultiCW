{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46641326-1e71-4d7a-a13b-e3584ab5cb1f",
   "metadata": {
    "id": "46641326-1e71-4d7a-a13b-e3584ab5cb1f"
   },
   "source": [
    "# Model fine-tuning\n",
    "### LESA model fine-tuning on MultiCW and OOD datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb7fd0d-9d7e-43be-9257-644125af64e9",
   "metadata": {
    "id": "3eb7fd0d-9d7e-43be-9257-644125af64e9"
   },
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9164a8d-2e16-45c1-b052-79ff7da7e8cc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Setup project paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4b1d6c59d2b5ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from os.path import join, exists\n",
    "from py_markdown_table.markdown_table import markdown_table\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Enable tqdm for pandas\n",
    "tqdm.pandas()\n",
    "\n",
    "# ANSI Highlighting: https://stackoverflow.com/a/21786287\n",
    "h_red = '\\x1b[1;30;41m'\n",
    "h_green = '\\x1b[1;30;42m'\n",
    "h_yellow = '\\x1b[1;30;43m'\n",
    "h_stop = '\\x1b[0m'\n",
    "\n",
    "## Setup project paths:\n",
    "project_path = os.getcwd()\n",
    "models_path = join(project_path, \"Models\")\n",
    "\n",
    "datasets_path = join(project_path, \"Source datasets\")\n",
    "multicw_path = join(project_path, 'Final-dataset')\n",
    "multiclaim_path = join(datasets_path, \"MultiClaim\")\n",
    "lesa_dst_dir = join(datasets_path, 'LESA-EACL-2021')\n",
    "lesa_model_path = join(models_path, 'LESA')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb31e5eb4ab1684",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Datasets\n",
    "Loading the MultiCW and OOD datasets for the purpose of models fine-tuning and their evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "585cff8b46c36f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded MultiCW:\n",
      "Train set: 88001\n",
      "Dev set: 14823\n",
      "Test set: 14823\n",
      "Out-of-dist set: 27761\n"
     ]
    }
   ],
   "source": [
    "# Load MultiCW model\n",
    "import pandas as pd\n",
    "from os.path import join\n",
    "languages = pd.read_csv(join('Final-dataset', 'multicw-full.csv'))['lang'].unique()\n",
    "\n",
    "multicw_path = join(\"Final-dataset\")\n",
    "multicw_train = pd.read_csv(join(multicw_path, \"multicw-train.csv\")).astype({'label':'int'})\n",
    "multicw_dev = pd.read_csv(join(multicw_path, \"multicw-dev.csv\")).astype({'label':'int'})\n",
    "multicw_test = pd.read_csv(join(multicw_path, \"multicw-test.csv\")).astype({'label':'int'})\n",
    "multicw_test = pd.read_csv(join(multicw_path, \"multicw-test.csv\")).astype({'text':'str'})\n",
    "multicw_ood = pd.read_csv(join(multicw_path, \"multicw-ood.csv\")).astype({'label':'int'})\n",
    "multicw_ood['style'] = multicw_ood['style'].replace('structured', 'struc')\n",
    "multicw_ood['text'] = multicw_ood['text'].fillna(\"\").astype(str)\n",
    "\n",
    "print(f'Loaded MultiCW:')\n",
    "print(f'Train set: {multicw_train.shape[0]}')\n",
    "print(f'Dev set: {multicw_dev.shape[0]}')\n",
    "print(f'Test set: {multicw_test.shape[0]}')\n",
    "print(f'Out-of-dist set: {multicw_ood.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07373bf5-a7a4-4a8f-a93a-d1054d4b07cf",
   "metadata": {
    "id": "07373bf5-a7a4-4a8f-a93a-d1054d4b07cf"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c090cbc1-47c5-4273-81de-eae6eabcb7b0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### LESA model (EACL-2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b7c3171-8222-4e7a-8612-05eb0184a180",
   "metadata": {
    "id": "2b7c3171-8222-4e7a-8612-05eb0184a180",
    "jupyter": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-01 14:03:38.037590: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-10-01 14:03:38.041216: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2025-10-01 14:03:38.204706: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2025-10-01 14:03:38.204769: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import warnings\n",
    "from typing import Callable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from pandas import DataFrame\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.optimizers import Adam\n",
    "from tqdm import tqdm\n",
    "from transformers import BertTokenizer, AutoTokenizer\n",
    "\n",
    "\n",
    "sys.path.insert(1, lesa_model_path)\n",
    "\n",
    "from loader import sent2feature2ngram, ParentPositions, tokenize_sentences, create_attention_masks, \\\n",
    "    load_embedding_matrix, load_tokenizer, ind_model_noisy, ind_model_semi, ind_model_structured, final\n",
    "\n",
    "# ANSI Highlighting: https://stackoverflow.com/a/21786287\n",
    "h_stop = '\\x1b[0m'\n",
    "gh_start = '\\x1b[1;30;42m'\n",
    "rh_start = '\\x1b[1;30;41m'\n",
    "\n",
    "\n",
    "class LESAClaimModel():\n",
    "    \"\"\" LESA: Linguistic Encapsulation and Semantic Amalgamation Based Generalised Claim Detection from Online\n",
    "    Content accepted at EACL 2021. ArXiv paper [link](https://arxiv.org/abs/2101.11891) \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.max_len = 30\n",
    "        self.batch_size = 32\n",
    "\n",
    "        self.final_model = None\n",
    "        self.noisy_model = None\n",
    "        self.semi_model = None\n",
    "        self.structured_model = None\n",
    "\n",
    "        self.noisy = None\n",
    "        self.noisy_dev = None\n",
    "        self.semi = None\n",
    "        self.semi_dev = None\n",
    "        self.struct = None\n",
    "        self.struct_dev = None\n",
    "\n",
    "        self.update_semantic_dbs = False\n",
    "\n",
    "        # Set default semantic embedding datasets\n",
    "        # self.set_semantic_datasets()\n",
    "\n",
    "        # Init tokenizers as class variables\n",
    "        print('Loading tokenizers: ', end='')\n",
    "\n",
    "        # Original BERT model\n",
    "        # model = os.path.join(lesa_model_path, 'bert-base')\n",
    "        # self.bert_tokenizer_transformer = BertTokenizer.from_pretrained(model, local_files_only=True)\n",
    "\n",
    "        # Multilingual BERT model\n",
    "        model = \"bert-base-multilingual-cased\"\n",
    "        self.bert_tokenizer_transformer = AutoTokenizer.from_pretrained(model)\n",
    "\n",
    "        # EMBEDDINGS\n",
    "        self.noisy_embedding_matrix_tag = load_embedding_matrix(lesa_model_path, 'embedding_matrix_tag_noisy.pickle')\n",
    "        self.noisy_vocab_size_tag = self.noisy_embedding_matrix_tag.shape[0]  # 5363\n",
    "\n",
    "        self.semi_embedding_matrix_tag = load_embedding_matrix(lesa_model_path, 'embedding_matrix_tag_semi.pickle')\n",
    "        self.semi_vocab_size_tag = self.semi_embedding_matrix_tag.shape[0]  # 6137\n",
    "\n",
    "        self.structured_embedding_matrix_tag = load_embedding_matrix(lesa_model_path, 'embedding_matrix_tag_structured.pickle')\n",
    "        self.structured_vocab_size_tag = self.structured_embedding_matrix_tag.shape[0]  # 6048\n",
    "\n",
    "        # PARENT POS TOKENIZER\n",
    "        self.tokenizer_dep_parent_noisy = load_tokenizer(lesa_model_path, 'tokenizer_dep_parent_noisy.pickle')\n",
    "        self.num_words_dep_parent_noisy = self.tokenizer_dep_parent_noisy.num_words  # 100\n",
    "\n",
    "        self.tokenizer_dep_parent_semi = load_tokenizer(lesa_model_path, 'tokenizer_dep_parent_semi.pickle')\n",
    "        self.num_words_dep_parent_semi = self.tokenizer_dep_parent_semi.num_words  # 200\n",
    "\n",
    "        self.tokenizer_dep_parent_structured = load_tokenizer(lesa_model_path, 'tokenizer_dep_parent_structured.pickle')\n",
    "        self.num_words_dep_parent_structured = self.tokenizer_dep_parent_structured.num_words  # 200\n",
    "\n",
    "        # LABEL TOKENIZER\n",
    "        self.tokenizer_dep_noisy = load_tokenizer(lesa_model_path, 'tokenizer_dep_noisy.pickle')\n",
    "        self.num_words_dep_noisy = self.tokenizer_dep_noisy.num_words  # 6300\n",
    "\n",
    "        self.tokenizer_dep_semi = load_tokenizer(lesa_model_path, 'tokenizer_dep_semi.pickle')\n",
    "        self.num_words_dep_semi = self.tokenizer_dep_semi.num_words  # 7300\n",
    "\n",
    "        self.tokenizer_dep_structured = load_tokenizer(lesa_model_path, 'tokenizer_dep_structured.pickle')\n",
    "        self.num_words_dep_structured = self.tokenizer_dep_structured.num_words  # 7400\n",
    "\n",
    "        # TAG TOKENIZER\n",
    "        self.tokenizer_tag_noisy = load_tokenizer(lesa_model_path, 'tokenizer_tag_noisy.pickle')\n",
    "        self.tokenizer_tag_semi = load_tokenizer(lesa_model_path, 'tokenizer_tag_semi.pickle')\n",
    "        self.tokenizer_tag_structured = load_tokenizer(lesa_model_path, 'tokenizer_tag_structured.pickle')\n",
    "        print('ok')\n",
    "\n",
    "        self.final_model = self._init_model()\n",
    "\n",
    "    def load_model(self, model_name='lesa2021') -> bool:\n",
    "        \"\"\"Loads the model from the file.\"\"\"\n",
    "\n",
    "        os.makedirs(models_path, exist_ok=True)\n",
    "\n",
    "        print(join(os.getcwd(), models_path, model_name))\n",
    "        if not os.path.exists(join(models_path, model_name)):\n",
    "            print(rh_start + 'Invalid path!' + h_stop)\n",
    "            return False\n",
    "\n",
    "        print(f'Loading {model_name} model: ', end='')\n",
    "        try:\n",
    "            self.noisy_model.load_weights(join(models_path, model_name, '_dep_noisy.h5'))\n",
    "            self.semi_model.load_weights(join(models_path, model_name, '_dep_semi.h5'))\n",
    "            self.structured_model.load_weights(join(models_path, model_name, '_dep_structured.h5'))\n",
    "\n",
    "            self.final_model.load_weights(join(models_path, model_name, '_bert_comb.h5'))\n",
    "\n",
    "            print(gh_start + \" ok\" + h_stop)\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            # print(e)\n",
    "            print(rh_start + \" failed!\" + h_stop)\n",
    "            return False\n",
    "\n",
    "    def detect_claims(self, test_set: DataFrame, verbose=False) -> tuple:\n",
    "        \"\"\"Performs inference on the testing data and evaluates results.\"\"\"\n",
    "\n",
    "        x = self.semantic_embeddings(test_set)\n",
    "\n",
    "        # testing\n",
    "        print('Running classification:')\n",
    "        metrics = self.final_model.predict(x)\n",
    "        results = [np.argmax(el) for el in metrics[-1]]\n",
    "        print('Done.')\n",
    "        # Print sentences with classifications\n",
    "        if verbose:\n",
    "            for i, text in enumerate(test_set['text']):\n",
    "                print(\"LESA classification: '{text}' {c} a claim.\".\n",
    "                      format(text=text, c=gh_start + \"is\" if results[i] == 1 else rh_start + \"is not\") + h_stop)\n",
    "\n",
    "        # compare against ground-truth\n",
    "        ground_truth = test_set['label']\n",
    "        report = classification_report(ground_truth, results, output_dict=True)\n",
    "        report_str = str(classification_report(ground_truth, results))\n",
    "\n",
    "        return report, report_str\n",
    "\n",
    "    def train_model(self, train_set: DataFrame, dev_set: DataFrame, epochs=1, learn_rate=3e-5, model_name='', lang='en'):\n",
    "        \"\"\"\n",
    "        Train the LESA-2021 model with the given parameters. The training consists of two phases:\n",
    "        - Pre-training of semantic modules with noisy, semi-noisy and structured data respectively\n",
    "        - Fine-tuning of the main BERT model together with the semantic model on the training data\n",
    "        :param learn_rate: Learning rate.\n",
    "        :param train_set: Training dataset.\n",
    "        :param dev_set: Validation dataset.\n",
    "        :param epochs: Number of training epochs.\n",
    "        :param model_name: Model will be saved to the directory named by this value.If left blank, the model won't save.\n",
    "        :param lang: Training dataset language(s). Needed for naming conventions.\n",
    "        :return: Trained model.\n",
    "        \"\"\"\n",
    "\n",
    "        model_name = f\"{model_name}-{lang}-{epochs}e\"\n",
    "        path = os.path.join(models_path, model_name)\n",
    "        semantic_path = os.path.join(lesa_model_path, 'semantic_base')\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "\n",
    "        if not self.update_semantic_dbs:\n",
    "            # Make sure that semantic models are loaded\n",
    "            shutil.copyfile(src=os.path.join(semantic_path, '_dep_noisy.h5'), dst=os.path.join(path, '_dep_noisy.h5'))\n",
    "            shutil.copyfile(src=os.path.join(semantic_path, '_dep_semi.h5'), dst=os.path.join(path, '_dep_semi.h5'))\n",
    "            shutil.copyfile(src=os.path.join(semantic_path, '_dep_structured.h5'), dst=os.path.join(path, '_dep_structured.h5'))\n",
    "\n",
    "            self.noisy_model.load_weights(os.path.join(semantic_path, '_dep_noisy.h5'))\n",
    "            self.semi_model.load_weights(os.path.join(semantic_path, '_dep_semi.h5'))\n",
    "            self.structured_model.load_weights(os.path.join(semantic_path, '_dep_structured.h5'))\n",
    "        else:\n",
    "            # If we use custom semantic models, make sure they are saved within the same folder as the model file\n",
    "            self.noisy_model.save_weights(os.path.join(path, '_dep_noisy.h5'))\n",
    "            print('Model saved to: ', os.path.join(path, '_dep_noisy.h5'))\n",
    "\n",
    "            self.semi_model.save_weights(os.path.join(path, '_dep_semi.h5'))\n",
    "            print('Model saved to: ', os.path.join(path, '_dep_semi.h5'))\n",
    "\n",
    "            self.structured_model.save_weights(os.path.join(path, '_dep_structured.h5'))\n",
    "            print('Model saved to: ', os.path.join(path, '_dep_structured.h5'))\n",
    "\n",
    "        print('Train Final model:')\n",
    "        x = self.semantic_embeddings(train_set)\n",
    "        dev = self.semantic_embeddings(dev_set)\n",
    "\n",
    "        self.final_model.optimizer = Adam(learning_rate=learn_rate)\n",
    "        self.final_model.fit(x=x, y=train_set['label'], batch_size=self.batch_size, epochs=epochs,\n",
    "                             validation_data=(dev, dev_set['label']))\n",
    "        self.final_model.save_weights(os.path.join(path, '_bert_comb.h5'))\n",
    "        print('Model saved to: ', os.path.join(path, '_bert_comb.h5'))\n",
    "\n",
    "    def _init_model(self):\n",
    "        # load_model\n",
    "        print(\"Initializing model architecture: \")\n",
    "\n",
    "        # aux CLAIMS-2023 model\n",
    "        self.noisy_model = ind_model_noisy(embed_dim=20, num_heads=5, ff_dim=128,\n",
    "                                           maxlen=self.max_len, vocab_label=self.num_words_dep_noisy,\n",
    "                                           vocab_parent_pos=self.num_words_dep_parent_noisy)\n",
    "\n",
    "        self.semi_model = ind_model_semi(embed_dim=20, num_heads=5, ff_dim=128,\n",
    "                                         maxlen=self.max_len, vocab_label=self.num_words_dep_semi,\n",
    "                                         vocab_parent_pos=self.num_words_dep_parent_semi)\n",
    "\n",
    "        self.structured_model = ind_model_structured(embed_dim=20, num_heads=5, ff_dim=128,\n",
    "                                                     maxlen=self.max_len, vocab_label=self.num_words_dep_structured,\n",
    "                                                     vocab_parent_pos=self.num_words_dep_parent_structured)\n",
    "\n",
    "        parameters_dict_noisy = {\n",
    "            \"vocab_size_tag\": self.noisy_vocab_size_tag,\n",
    "            \"EMBEDDING_DIM_TAG\": 20,\n",
    "            \"embedding_matrix_tag\": self.noisy_embedding_matrix_tag,\n",
    "            \"maxlen_tag\": self.max_len\n",
    "        }\n",
    "\n",
    "        parameters_dict_semi = {\n",
    "            \"vocab_size_tag\": self.semi_vocab_size_tag,\n",
    "            \"EMBEDDING_DIM_TAG\": 20,\n",
    "            \"embedding_matrix_tag\": self.semi_embedding_matrix_tag,\n",
    "            \"maxlen_tag\": self.max_len\n",
    "        }\n",
    "\n",
    "        parameters_dict_structured = {\n",
    "            \"vocab_size_tag\": self.structured_vocab_size_tag,\n",
    "            \"EMBEDDING_DIM_TAG\": 20,\n",
    "            \"embedding_matrix_tag\": self.structured_embedding_matrix_tag,\n",
    "            \"maxlen_tag\": self.max_len\n",
    "        }\n",
    "\n",
    "        final_model = final(lesa_model_path, self.noisy_model, self.semi_model, self.structured_model, parameters_dict_noisy,\n",
    "                            parameters_dict_semi, parameters_dict_structured, max_seq_length=60)\n",
    "\n",
    "        print('ok')\n",
    "\n",
    "        return final_model\n",
    "\n",
    "    def semantic_embeddings(self, dataset: DataFrame):\n",
    "        # GET SYNTACTIC REP: TEST\n",
    "        # Assuming 'original_dataset' is your original DataFrame\n",
    "        dataset = dataset.copy()\n",
    "\n",
    "        print(\"Getting dependency and POS tags...\")\n",
    "\n",
    "        # Processing DEP tags\n",
    "        progress = tqdm(dataset['text'].copy())\n",
    "        progress.set_description('sentence2pos tags:')\n",
    "        dataset.loc[:, 'DEP'] = [sent2feature2ngram(row) for row in progress]\n",
    "\n",
    "        # Processing parent POS tags\n",
    "        progress = tqdm(dataset['text'].copy())\n",
    "        progress.set_description('Parent POS tags:')\n",
    "        dataset.loc[:, \"parent_pos\"] = [ParentPositions(row) for row in progress]\n",
    "\n",
    "        # Processing TAG tags\n",
    "        progress = tqdm(dataset['text'].copy())\n",
    "        progress.set_description('sentence2tag tags:')\n",
    "        dataset.loc[:, 'TAG'] = [sent2feature2ngram(row, feature=\"TAG\") for row in progress]\n",
    "\n",
    "        print(\"POS Tags: complete!\")\n",
    "\n",
    "        # COMMON TEST REP | DEP\n",
    "        print(\"Getting dependency and DEP tags...\")\n",
    "        noisy = self.tokenizer_dep_noisy.texts_to_sequences(dataset['DEP'])\n",
    "        semi = self.tokenizer_dep_semi.texts_to_sequences(dataset['DEP'])\n",
    "        structured = self.tokenizer_dep_structured.texts_to_sequences(dataset['DEP'])\n",
    "\n",
    "        p_noisy = self.tokenizer_dep_parent_noisy.texts_to_sequences(dataset['parent_pos'])\n",
    "        p_semi = self.tokenizer_dep_parent_semi.texts_to_sequences(dataset['parent_pos'])\n",
    "        p_structured = self.tokenizer_dep_parent_structured.texts_to_sequences(dataset['parent_pos'])\n",
    "\n",
    "        noisy = pad_sequences(noisy, maxlen=self.max_len)\n",
    "        semi = pad_sequences(semi, maxlen=self.max_len)\n",
    "        structured = pad_sequences(structured, maxlen=self.max_len)\n",
    "\n",
    "        p_noisy = pad_sequences(p_noisy, maxlen=self.max_len)\n",
    "        p_semi = pad_sequences(p_semi, maxlen=self.max_len)\n",
    "        p_structured = pad_sequences(p_structured, maxlen=self.max_len)\n",
    "\n",
    "        print(\"DEP Tags: complete!\")\n",
    "\n",
    "        # BERT REP: TEST\n",
    "        print(\"Creating BERT Embeddings...\")\n",
    "        input_ids = tokenize_sentences(dataset['text'], self.bert_tokenizer_transformer, 60)\n",
    "        input_ids = pad_sequences(input_ids, maxlen=60, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\n",
    "        attention_masks = create_attention_masks(input_ids)\n",
    "\n",
    "        # COMMON TEST REP | TAG\n",
    "        tag_noisy = self.tokenizer_tag_noisy.texts_to_sequences(dataset['TAG'])\n",
    "        tag_semi = self.tokenizer_tag_semi.texts_to_sequences(dataset['TAG'])\n",
    "        tag_structured = self.tokenizer_tag_structured.texts_to_sequences(dataset['TAG'])\n",
    "\n",
    "        noisy[noisy >= self.noisy_vocab_size_tag] = self.noisy_vocab_size_tag - 1\n",
    "        p_noisy[p_noisy >= self.noisy_vocab_size_tag] = self.noisy_vocab_size_tag - 1\n",
    "        tag_noisy = np.array([np.array(x) for x in tqdm(tag_noisy)], dtype=object)\n",
    "        for arrays in tag_noisy:\n",
    "            arrays[arrays >= self.noisy_vocab_size_tag] = self.noisy_vocab_size_tag - 1\n",
    "\n",
    "        tag_noisy = pad_sequences(tag_noisy, maxlen=self.max_len)\n",
    "        tag_semi = pad_sequences(tag_semi, maxlen=self.max_len)\n",
    "        tag_structured = pad_sequences(tag_structured, maxlen=self.max_len)\n",
    "\n",
    "        x = {\"label_noisy\": np.array(noisy), \"parent_pos_noisy\": np.array(p_noisy),\n",
    "             \"label_semi\": np.array(semi), \"parent_pos_semi\": np.array(p_semi),\n",
    "             \"label_structured\": np.array(structured),\n",
    "             \"parent_pos_structured\": np.array(p_structured),\n",
    "             \"inp_noisy\": np.array(tag_noisy),\n",
    "             \"inp_semi\": np.array(tag_semi),\n",
    "             \"inp_structured\": np.array(tag_structured),\n",
    "             'input_word_ids': np.array(input_ids), 'input_masks': np.array(attention_masks)}\n",
    "\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5104ea-1327-4fbd-bd6b-edcbec967bd4",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dd05912ce3053e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Models fine-tuning on MultiCW dataset\n",
    "- Fine-tuning of xlm-RoBERTa, mDeBERTa anb LESA models on MultiCW train set\n",
    "- Evaluation on MultiCW test set\n",
    "#### LESA model:\n",
    "<table>\n",
    "<tr>\n",
    "<td>\n",
    "\n",
    "| Class            | Precision | Recall | F1‑score | Support   |\n",
    "| ---------------- | --------- | ------ | -------- | --------- |\n",
    "| 0                | **0.84**  | **0.72** | **0.78** | 9269      |\n",
    "| 1                | **0.75**  | **0.87** | **0.80** | 9164      |\n",
    "| **Accuracy**     |           |        | **0.79** | **18433** |\n",
    "| **Macro avg**    | 0.80      | 0.79   | 0.79     | 18433     |\n",
    "| **Weighted avg** | 0.80      | 0.79   | 0.79     | 18433     |\n",
    "                    MultiCW Overall.\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "| Class            | Precision | Recall | F1‑score | Support  |\n",
    "| ---------------- | --------- | ------ | -------- | -------- |\n",
    "| 0                | **0.78**  | **0.57** | **0.66** | 4744     |\n",
    "| 1                | **0.66**  | **0.83** | **0.73** | 4639     |\n",
    "| **Accuracy**     |           |        | **0.70** | **9383** |\n",
    "| **Macro avg**    | 0.72      | 0.70   | 0.70     | 9383      |\n",
    "| **Weighted avg** | 0.72      | 0.70   | 0.70     | 9383      |\n",
    "                MultiCW Noisy Part.\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "| Class            | Precision | Recall | F1‑score | Support  |\n",
    "| ---------------- | --------- | ------ | -------- | -------- |\n",
    "| 0                | **0.89**  | **0.87** | **0.88** | 4525     |\n",
    "| 1                | **0.88**  | **0.90** | **0.89** | 4525     |\n",
    "| **Accuracy**     |           |        | **0.88** | **9050** |\n",
    "| **Macro avg**    | 0.88      | 0.88   | 0.88     | 9050     |\n",
    "| **Weighted avg** | 0.88      | 0.88   | 0.88     | 9050     |\n",
    "                MultiCW Structured Part.\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c67e86a4-96fa-4fc9-bc1f-5d7ee253bf73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;42mLESA model:\u001b[0m\n",
      "Loading tokenizers: ok\n",
      "Initializing model architecture: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyben/.conda/envs/MultiCW-lesa/lib/python3.10/site-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n",
      "All model checkpoint layers were used when initializing TFBertModel.\n",
      "\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at /home/hyben/KInIT/Projects/veraAI/T4.1-Claim detection/MultiCW/Models/LESA/bert-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
      "sentence2pos tags::  14%|██             | 1269/9394 [1:18:57<8:25:30,  3.73s/it]\n",
      "Some layers from the model checkpoint at bert-base-multilingual-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-multilingual-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "/home/hyben/KInIT/Projects/veraAI/T4.1-Claim detection/MultiCW/Models/lesa-multicw-2e6-5e\n",
      "Loading lesa-multicw-2e6-5e model: \u001b[1;30;42m ok\u001b[0m\n",
      "\u001b[1;30;42mMultiCW overall:\u001b[0m\n",
      "Getting dependency and POS tags...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentence2pos tags:: 100%|████████████████| 18433/18433 [01:40<00:00, 182.53it/s]\n",
      "Parent POS tags:: 100%|██████████████████| 18433/18433 [01:33<00:00, 197.40it/s]\n",
      "sentence2tag tags:: 100%|████████████████| 18433/18433 [01:50<00:00, 166.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Tags: complete!\n",
      "Getting dependency and DEP tags...\n",
      "DEP Tags: complete!\n",
      "Creating BERT Embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 18433/18433 [00:03<00:00, 5535.35it/s]\n",
      "100%|█████████████████████████████████| 18433/18433 [00:00<00:00, 271617.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running classification:\n",
      "577/577 [==============================] - 498s 857ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.72      0.78      9269\n",
      "           1       0.75      0.87      0.80      9164\n",
      "\n",
      "    accuracy                           0.79     18433\n",
      "   macro avg       0.80      0.79      0.79     18433\n",
      "weighted avg       0.80      0.79      0.79     18433\n",
      "\n",
      "Getting dependency and POS tags...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentence2pos tags:: 100%|██████████████████| 9383/9383 [00:40<00:00, 231.20it/s]\n",
      "Parent POS tags:: 100%|████████████████████| 9383/9383 [00:37<00:00, 253.46it/s]\n",
      "sentence2tag tags:: 100%|██████████████████| 9383/9383 [00:36<00:00, 254.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Tags: complete!\n",
      "Getting dependency and DEP tags...\n",
      "DEP Tags: complete!\n",
      "Creating BERT Embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 9383/9383 [00:00<00:00, 10628.28it/s]\n",
      "100%|███████████████████████████████████| 9383/9383 [00:00<00:00, 383593.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running classification:\n",
      "294/294 [==============================] - 210s 713ms/step\n",
      "Done.\n",
      "\u001b[1;30;43mMultiCW Noisy Part:\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.57      0.66      4744\n",
      "           1       0.66      0.83      0.73      4639\n",
      "\n",
      "    accuracy                           0.70      9383\n",
      "   macro avg       0.72      0.70      0.70      9383\n",
      "weighted avg       0.72      0.70      0.70      9383\n",
      "\n",
      "Getting dependency and POS tags...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentence2pos tags:: 100%|██████████████████| 9050/9050 [00:34<00:00, 262.05it/s]\n",
      "Parent POS tags:: 100%|████████████████████| 9050/9050 [00:33<00:00, 266.80it/s]\n",
      "sentence2tag tags:: 100%|██████████████████| 9050/9050 [00:34<00:00, 265.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Tags: complete!\n",
      "Getting dependency and DEP tags...\n",
      "DEP Tags: complete!\n",
      "Creating BERT Embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 9050/9050 [00:00<00:00, 12492.62it/s]\n",
      "100%|███████████████████████████████████| 9050/9050 [00:00<00:00, 409896.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running classification:\n",
      "283/283 [==============================] - 202s 713ms/step\n",
      "Done.\n",
      "\u001b[1;30;43mMultiCW Structured Part:\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.87      0.88      4525\n",
      "           1       0.88      0.90      0.89      4525\n",
      "\n",
      "    accuracy                           0.88      9050\n",
      "   macro avg       0.88      0.88      0.88      9050\n",
      "weighted avg       0.88      0.88      0.88      9050\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'{h_green}LESA model:{h_stop}')\n",
    "detector = LESAClaimModel()\n",
    "\n",
    "if not detector.load_model(model_name=f'lesa-multicw-2e6-5e'):\n",
    "    print(f'{h_yellow}No model found. Initiating fine-tuning:{h_stop}')\n",
    "    # Note: Works well with a small learning rate (e.g. 3e-6)\n",
    "    detector.train_model(multicw_train, multicw_dev, epochs=5, learn_rate=2e-6, lang='en', model_name=f'lesa-multicw')\n",
    "\n",
    "print(f'{h_green}MultiCW overall:{h_stop}')\n",
    "_, report = detector.detect_claims(multicw_test)\n",
    "print(report)\n",
    "\n",
    "test_noisy = multicw_test.loc[multicw_test['style']=='noisy']\n",
    "_, report = detector.detect_claims(test_noisy, verbose=False)\n",
    "print(f'{h_yellow}MultiCW Noisy Part:{h_stop}')\n",
    "print(report)\n",
    "\n",
    "test_struc = multicw_test.loc[multicw_test['style']=='struct']\n",
    "_, report = detector.detect_claims(test_struc, verbose=False)\n",
    "print(f'{h_yellow}MultiCW Structured Part:{h_stop}')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f82d99-a8bc-478f-83b9-2842f01287d5",
   "metadata": {},
   "source": [
    "### Evaluation of LESA model on each language of the MultiCW dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34b3c354-d48f-42ab-a008-13d67ce339c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;42mLESA model:\u001b[0m\n",
      "Loading tokenizers: ok\n",
      "Initializing model architecture: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-25 21:01:36.669532: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/hyben/.conda/envs/MultiCW-lesa/lib/python3.10/site-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n",
      "All model checkpoint layers were used when initializing TFBertModel.\n",
      "\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at /home/hyben/KInIT/Projects/veraAI/T4.1-Claim detection/MultiCW/Models/LESA/bert-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
      "Some layers from the model checkpoint at bert-base-multilingual-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-multilingual-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "/home/hyben/KInIT/Projects/veraAI/T4.1-Claim detection/MultiCW/Models/lesa-multicw-2e6-5e\n",
      "Loading lesa-multicw-2e6-5e model: \u001b[1;30;42m ok\u001b[0m\n",
      "\u001b[1;30;43mLanguage: sk:\u001b[0m\n",
      "Getting dependency and POS tags...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentence2pos tags:: 100%|██████████████████| 1192/1192 [00:05<00:00, 206.90it/s]\n",
      "Parent POS tags:: 100%|████████████████████| 1192/1192 [00:05<00:00, 225.29it/s]\n",
      "sentence2tag tags:: 100%|██████████████████| 1192/1192 [00:06<00:00, 189.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Tags: complete!\n",
      "Getting dependency and DEP tags...\n",
      "DEP Tags: complete!\n",
      "Creating BERT Embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 1192/1192 [00:00<00:00, 11538.16it/s]\n",
      "100%|███████████████████████████████████| 1192/1192 [00:00<00:00, 378185.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running classification:\n",
      "38/38 [==============================] - 31s 754ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.73      0.77       596\n",
      "         1.0       0.75      0.82      0.79       596\n",
      "\n",
      "    accuracy                           0.78      1192\n",
      "   macro avg       0.78      0.78      0.78      1192\n",
      "weighted avg       0.78      0.78      0.78      1192\n",
      "\n",
      "\u001b[1;30;43mLanguage: pl:\u001b[0m\n",
      "Getting dependency and POS tags...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentence2pos tags:: 100%|██████████████████| 1194/1194 [00:05<00:00, 206.37it/s]\n",
      "Parent POS tags:: 100%|████████████████████| 1194/1194 [00:04<00:00, 243.47it/s]\n",
      "sentence2tag tags:: 100%|██████████████████| 1194/1194 [00:04<00:00, 257.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Tags: complete!\n",
      "Getting dependency and DEP tags...\n",
      "DEP Tags: complete!\n",
      "Creating BERT Embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 1194/1194 [00:00<00:00, 12512.21it/s]\n",
      "100%|███████████████████████████████████| 1194/1194 [00:00<00:00, 338836.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running classification:\n",
      "38/38 [==============================] - 31s 805ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.77      0.82       597\n",
      "         1.0       0.79      0.89      0.84       597\n",
      "\n",
      "    accuracy                           0.83      1194\n",
      "   macro avg       0.83      0.83      0.83      1194\n",
      "weighted avg       0.83      0.83      0.83      1194\n",
      "\n",
      "\u001b[1;30;43mLanguage: cs:\u001b[0m\n",
      "Getting dependency and POS tags...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentence2pos tags:: 100%|██████████████████| 1192/1192 [00:05<00:00, 211.37it/s]\n",
      "Parent POS tags:: 100%|████████████████████| 1192/1192 [00:05<00:00, 222.38it/s]\n",
      "sentence2tag tags:: 100%|██████████████████| 1192/1192 [00:04<00:00, 241.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Tags: complete!\n",
      "Getting dependency and DEP tags...\n",
      "DEP Tags: complete!\n",
      "Creating BERT Embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 1192/1192 [00:00<00:00, 10386.92it/s]\n",
      "100%|███████████████████████████████████| 1192/1192 [00:00<00:00, 381271.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running classification:\n",
      "38/38 [==============================] - 27s 722ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.78      0.78       596\n",
      "         1.0       0.78      0.78      0.78       596\n",
      "\n",
      "    accuracy                           0.78      1192\n",
      "   macro avg       0.78      0.78      0.78      1192\n",
      "weighted avg       0.78      0.78      0.78      1192\n",
      "\n",
      "\u001b[1;30;43mLanguage: bg:\u001b[0m\n",
      "Getting dependency and POS tags...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentence2pos tags:: 100%|██████████████████| 1060/1060 [00:05<00:00, 205.95it/s]\n",
      "Parent POS tags:: 100%|████████████████████| 1060/1060 [00:04<00:00, 241.05it/s]\n",
      "sentence2tag tags:: 100%|██████████████████| 1060/1060 [00:05<00:00, 206.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Tags: complete!\n",
      "Getting dependency and DEP tags...\n",
      "DEP Tags: complete!\n",
      "Creating BERT Embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 1060/1060 [00:00<00:00, 2798.30it/s]\n",
      "100%|███████████████████████████████████| 1060/1060 [00:00<00:00, 362432.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running classification:\n",
      "34/34 [==============================] - 27s 793ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.45      0.49       530\n",
      "         1.0       0.53      0.61      0.57       530\n",
      "\n",
      "    accuracy                           0.53      1060\n",
      "   macro avg       0.53      0.53      0.53      1060\n",
      "weighted avg       0.53      0.53      0.53      1060\n",
      "\n",
      "\u001b[1;30;43mLanguage: ru:\u001b[0m\n",
      "Getting dependency and POS tags...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentence2pos tags:: 100%|██████████████████| 1194/1194 [00:04<00:00, 255.25it/s]\n",
      "Parent POS tags:: 100%|████████████████████| 1194/1194 [00:04<00:00, 265.45it/s]\n",
      "sentence2tag tags:: 100%|██████████████████| 1194/1194 [00:04<00:00, 265.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Tags: complete!\n",
      "Getting dependency and DEP tags...\n",
      "DEP Tags: complete!\n",
      "Creating BERT Embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 1194/1194 [00:00<00:00, 11253.60it/s]\n",
      "100%|███████████████████████████████████| 1194/1194 [00:00<00:00, 406526.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running classification:\n",
      "38/38 [==============================] - 33s 880ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.85      0.86       597\n",
      "         1.0       0.85      0.86      0.86       597\n",
      "\n",
      "    accuracy                           0.86      1194\n",
      "   macro avg       0.86      0.86      0.86      1194\n",
      "weighted avg       0.86      0.86      0.86      1194\n",
      "\n",
      "\u001b[1;30;43mLanguage: uk:\u001b[0m\n",
      "Getting dependency and POS tags...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentence2pos tags:: 100%|██████████████████| 1190/1190 [00:06<00:00, 191.15it/s]\n",
      "Parent POS tags:: 100%|████████████████████| 1190/1190 [00:05<00:00, 236.81it/s]\n",
      "sentence2tag tags:: 100%|██████████████████| 1190/1190 [00:07<00:00, 165.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Tags: complete!\n",
      "Getting dependency and DEP tags...\n",
      "DEP Tags: complete!\n",
      "Creating BERT Embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 1190/1190 [00:00<00:00, 3818.37it/s]\n",
      "100%|███████████████████████████████████| 1190/1190 [00:00<00:00, 398246.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running classification:\n",
      "38/38 [==============================] - 30s 779ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.81      0.81       595\n",
      "         1.0       0.81      0.81      0.81       595\n",
      "\n",
      "    accuracy                           0.81      1190\n",
      "   macro avg       0.81      0.81      0.81      1190\n",
      "weighted avg       0.81      0.81      0.81      1190\n",
      "\n",
      "\u001b[1;30;43mLanguage: zh:\u001b[0m\n",
      "Getting dependency and POS tags...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentence2pos tags:: 100%|██████████████████| 1034/1034 [00:04<00:00, 255.00it/s]\n",
      "Parent POS tags:: 100%|████████████████████| 1034/1034 [00:02<00:00, 371.56it/s]\n",
      "sentence2tag tags:: 100%|██████████████████| 1034/1034 [00:03<00:00, 341.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Tags: complete!\n",
      "Getting dependency and DEP tags...\n",
      "DEP Tags: complete!\n",
      "Creating BERT Embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 1034/1034 [00:00<00:00, 11459.00it/s]\n",
      "100%|███████████████████████████████████| 1034/1034 [00:00<00:00, 485113.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running classification:\n",
      "33/33 [==============================] - 24s 730ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.80      0.84       517\n",
      "         1.0       0.82      0.88      0.85       517\n",
      "\n",
      "    accuracy                           0.84      1034\n",
      "   macro avg       0.85      0.84      0.84      1034\n",
      "weighted avg       0.85      0.84      0.84      1034\n",
      "\n",
      "\u001b[1;30;43mLanguage: hi:\u001b[0m\n",
      "Getting dependency and POS tags...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentence2pos tags:: 100%|██████████████████| 1194/1194 [00:05<00:00, 232.89it/s]\n",
      "Parent POS tags:: 100%|████████████████████| 1194/1194 [00:04<00:00, 255.46it/s]\n",
      "sentence2tag tags:: 100%|██████████████████| 1194/1194 [00:04<00:00, 257.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Tags: complete!\n",
      "Getting dependency and DEP tags...\n",
      "DEP Tags: complete!\n",
      "Creating BERT Embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 1194/1194 [00:00<00:00, 12070.75it/s]\n",
      "100%|███████████████████████████████████| 1194/1194 [00:00<00:00, 402119.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running classification:\n",
      "38/38 [==============================] - 29s 764ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.79      0.86       597\n",
      "         1.0       0.82      0.94      0.88       597\n",
      "\n",
      "    accuracy                           0.87      1194\n",
      "   macro avg       0.88      0.87      0.87      1194\n",
      "weighted avg       0.88      0.87      0.87      1194\n",
      "\n",
      "\u001b[1;30;43mLanguage: en:\u001b[0m\n",
      "Getting dependency and POS tags...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentence2pos tags:: 100%|██████████████████| 1200/1200 [00:08<00:00, 149.62it/s]\n",
      "Parent POS tags:: 100%|████████████████████| 1200/1200 [00:08<00:00, 148.51it/s]\n",
      "sentence2tag tags:: 100%|██████████████████| 1200/1200 [00:05<00:00, 213.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Tags: complete!\n",
      "Getting dependency and DEP tags...\n",
      "DEP Tags: complete!\n",
      "Creating BERT Embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 1200/1200 [00:00<00:00, 10665.16it/s]\n",
      "100%|███████████████████████████████████| 1200/1200 [00:00<00:00, 379060.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running classification:\n",
      "38/38 [==============================] - 29s 750ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.67      0.68       600\n",
      "         1.0       0.68      0.70      0.69       600\n",
      "\n",
      "    accuracy                           0.68      1200\n",
      "   macro avg       0.68      0.68      0.68      1200\n",
      "weighted avg       0.68      0.68      0.68      1200\n",
      "\n",
      "\u001b[1;30;43mLanguage: ar:\u001b[0m\n",
      "Getting dependency and POS tags...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentence2pos tags:: 100%|██████████████████| 1198/1198 [00:09<00:00, 131.85it/s]\n",
      "Parent POS tags:: 100%|████████████████████| 1198/1198 [00:05<00:00, 218.49it/s]\n",
      "sentence2tag tags:: 100%|██████████████████| 1198/1198 [00:05<00:00, 200.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Tags: complete!\n",
      "Getting dependency and DEP tags...\n",
      "DEP Tags: complete!\n",
      "Creating BERT Embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 1198/1198 [00:00<00:00, 9699.31it/s]\n",
      "100%|███████████████████████████████████| 1198/1198 [00:00<00:00, 382723.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running classification:\n",
      "38/38 [==============================] - 33s 880ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.48      0.59       599\n",
      "         1.0       0.62      0.86      0.72       599\n",
      "\n",
      "    accuracy                           0.67      1198\n",
      "   macro avg       0.70      0.67      0.66      1198\n",
      "weighted avg       0.70      0.67      0.66      1198\n",
      "\n",
      "\u001b[1;30;43mLanguage: es:\u001b[0m\n",
      "Getting dependency and POS tags...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentence2pos tags:: 100%|██████████████████| 1198/1198 [00:08<00:00, 138.44it/s]\n",
      "Parent POS tags:: 100%|████████████████████| 1198/1198 [00:07<00:00, 167.36it/s]\n",
      "sentence2tag tags:: 100%|██████████████████| 1198/1198 [00:08<00:00, 134.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Tags: complete!\n",
      "Getting dependency and DEP tags...\n",
      "DEP Tags: complete!\n",
      "Creating BERT Embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 1198/1198 [00:00<00:00, 3366.34it/s]\n",
      "100%|███████████████████████████████████| 1198/1198 [00:00<00:00, 176648.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running classification:\n",
      "38/38 [==============================] - 34s 904ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.63      0.72       599\n",
      "         1.0       0.71      0.89      0.79       599\n",
      "\n",
      "    accuracy                           0.76      1198\n",
      "   macro avg       0.78      0.76      0.76      1198\n",
      "weighted avg       0.78      0.76      0.76      1198\n",
      "\n",
      "\u001b[1;30;43mLanguage: fr:\u001b[0m\n",
      "Getting dependency and POS tags...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentence2pos tags:: 100%|██████████████████| 1194/1194 [00:07<00:00, 161.88it/s]\n",
      "Parent POS tags:: 100%|████████████████████| 1194/1194 [00:05<00:00, 215.16it/s]\n",
      "sentence2tag tags:: 100%|██████████████████| 1194/1194 [00:07<00:00, 150.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Tags: complete!\n",
      "Getting dependency and DEP tags...\n",
      "DEP Tags: complete!\n",
      "Creating BERT Embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 1194/1194 [00:00<00:00, 13575.53it/s]\n",
      "100%|███████████████████████████████████| 1194/1194 [00:00<00:00, 442090.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running classification:\n",
      "38/38 [==============================] - 30s 800ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.83      0.88       597\n",
      "         1.0       0.84      0.94      0.89       597\n",
      "\n",
      "    accuracy                           0.88      1194\n",
      "   macro avg       0.89      0.88      0.88      1194\n",
      "weighted avg       0.89      0.88      0.88      1194\n",
      "\n",
      "\u001b[1;30;43mLanguage: tr:\u001b[0m\n",
      "Getting dependency and POS tags...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentence2pos tags:: 100%|██████████████████| 1184/1184 [00:06<00:00, 190.06it/s]\n",
      "Parent POS tags:: 100%|████████████████████| 1184/1184 [00:05<00:00, 236.55it/s]\n",
      "sentence2tag tags:: 100%|██████████████████| 1184/1184 [00:05<00:00, 212.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Tags: complete!\n",
      "Getting dependency and DEP tags...\n",
      "DEP Tags: complete!\n",
      "Creating BERT Embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 1184/1184 [00:00<00:00, 9649.72it/s]\n",
      "100%|███████████████████████████████████| 1184/1184 [00:00<00:00, 388732.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running classification:\n",
      "37/37 [==============================] - 29s 795ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.48      0.60       592\n",
      "         1.0       0.63      0.87      0.73       592\n",
      "\n",
      "    accuracy                           0.68      1184\n",
      "   macro avg       0.71      0.68      0.66      1184\n",
      "weighted avg       0.71      0.68      0.66      1184\n",
      "\n",
      "\u001b[1;30;43mLanguage: bn:\u001b[0m\n",
      "Getting dependency and POS tags...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentence2pos tags:: 100%|████████████████████| 930/930 [00:05<00:00, 182.19it/s]\n",
      "Parent POS tags:: 100%|██████████████████████| 930/930 [00:03<00:00, 271.75it/s]\n",
      "sentence2tag tags:: 100%|████████████████████| 930/930 [00:03<00:00, 260.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Tags: complete!\n",
      "Getting dependency and DEP tags...\n",
      "DEP Tags: complete!\n",
      "Creating BERT Embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 930/930 [00:00<00:00, 11298.56it/s]\n",
      "100%|█████████████████████████████████████| 930/930 [00:00<00:00, 428931.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running classification:\n",
      "30/30 [==============================] - 26s 874ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.69      0.79       465\n",
      "         1.0       0.75      0.95      0.84       465\n",
      "\n",
      "    accuracy                           0.82       930\n",
      "   macro avg       0.84      0.82      0.81       930\n",
      "weighted avg       0.84      0.82      0.81       930\n",
      "\n",
      "\u001b[1;30;43mLanguage: pt:\u001b[0m\n",
      "Getting dependency and POS tags...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentence2pos tags:: 100%|██████████████████| 1194/1194 [00:09<00:00, 126.76it/s]\n",
      "Parent POS tags:: 100%|█████████████████████| 1194/1194 [00:12<00:00, 93.25it/s]\n",
      "sentence2tag tags:: 100%|██████████████████| 1194/1194 [00:07<00:00, 158.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Tags: complete!\n",
      "Getting dependency and DEP tags...\n",
      "DEP Tags: complete!\n",
      "Creating BERT Embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 1194/1194 [00:00<00:00, 12515.49it/s]\n",
      "100%|███████████████████████████████████| 1194/1194 [00:00<00:00, 394765.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running classification:\n",
      "38/38 [==============================] - 28s 746ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.86      0.91       597\n",
      "         1.0       0.87      0.96      0.92       597\n",
      "\n",
      "    accuracy                           0.91      1194\n",
      "   macro avg       0.92      0.91      0.91      1194\n",
      "weighted avg       0.92      0.91      0.91      1194\n",
      "\n",
      "\u001b[1;30;43mLanguage: de:\u001b[0m\n",
      "Getting dependency and POS tags...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentence2pos tags:: 100%|██████████████████| 1192/1192 [00:05<00:00, 237.81it/s]\n",
      "Parent POS tags:: 100%|████████████████████| 1192/1192 [00:04<00:00, 255.31it/s]\n",
      "sentence2tag tags:: 100%|██████████████████| 1192/1192 [00:05<00:00, 228.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Tags: complete!\n",
      "Getting dependency and DEP tags...\n",
      "DEP Tags: complete!\n",
      "Creating BERT Embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 1192/1192 [00:00<00:00, 12520.03it/s]\n",
      "100%|███████████████████████████████████| 1192/1192 [00:00<00:00, 390411.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running classification:\n",
      "38/38 [==============================] - 30s 796ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.85      0.88       596\n",
      "         1.0       0.86      0.91      0.89       596\n",
      "\n",
      "    accuracy                           0.88      1192\n",
      "   macro avg       0.88      0.88      0.88      1192\n",
      "weighted avg       0.88      0.88      0.88      1192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'{h_green}LESA model:{h_stop}')\n",
    "detector = LESAClaimModel()\n",
    "\n",
    "if not detector.load_model(model_name=f'lesa-multicw-2e6-5e'):\n",
    "    print(f'{h_yellow}No model found. Initiating fine-tuning:{h_stop}')\n",
    "    # Note: Works well with a small learning rate (e.g. 3e-6)\n",
    "    detector.train_model(multicw_train, multicw_dev, epochs=5, learn_rate=2e-6, lang='en', model_name=f'lesa-multicw')\n",
    "\n",
    "languages = multicw_test['lang'].unique()\n",
    "\n",
    "for lang in languages:\n",
    "    print(f'{h_yellow}Language: {lang}:{h_stop}')\n",
    "    _, report = detector.detect_claims(multicw_test[multicw_test['lang'] == lang])\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f43847a8ba1952a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Out-domain evaluation\n",
    "- Evaluation of the fine-tuned models on manually obtained samples from factcheck.afp.com and with the preprocessing applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2e6f104-4696-4390-9d44-b9e40b88c988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;42mLESA model:\u001b[0m\n",
      "Loading tokenizers: ok\n",
      "Initializing model architecture: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-01 14:04:10.484076: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/hyben/.conda/envs/MultiCW-lesa/lib/python3.10/site-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n",
      "All model checkpoint layers were used when initializing TFBertModel.\n",
      "\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at /home/hyben/KInIT/Projects/veraAI/T4.1-Claim detection/MultiCW/Models/LESA/bert-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
      "2025-10-01 14:04:16.227942: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 367248384 exceeds 10% of free system memory.\n",
      "2025-10-01 14:04:16.387841: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 367248384 exceeds 10% of free system memory.\n",
      "2025-10-01 14:04:16.419176: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 367248384 exceeds 10% of free system memory.\n",
      "2025-10-01 14:04:17.610444: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 367248384 exceeds 10% of free system memory.\n",
      "2025-10-01 14:04:17.895718: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 367248384 exceeds 10% of free system memory.\n",
      "Some layers from the model checkpoint at bert-base-multilingual-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-multilingual-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "/home/hyben/KInIT/Projects/veraAI/T4.1-Claim detection/MultiCW/Models/lesa-multicw-2e6-5e\n",
      "Loading lesa-multicw-2e6-5e model: \u001b[1;30;42m ok\u001b[0m\n",
      "\u001b[1;30;42mMultiCW overall:\u001b[0m\n",
      "Getting dependency and POS tags...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentence2pos tags:: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 27761/27761 [01:56<00:00, 237.97it/s]\n",
      "Parent POS tags:: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 27761/27761 [01:50<00:00, 250.17it/s]\n",
      "sentence2tag tags:: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 27761/27761 [01:54<00:00, 242.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Tags: complete!\n",
      "Getting dependency and DEP tags...\n",
      "DEP Tags: complete!\n",
      "Creating BERT Embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27761/27761 [00:03<00:00, 7511.49it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27761/27761 [00:00<00:00, 409996.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running classification:\n",
      "868/868 [==============================] - 646s 741ms/step\n",
      "Done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.64      0.73     15997\n",
      "           1       0.64      0.86      0.73     11764\n",
      "\n",
      "    accuracy                           0.73     27761\n",
      "   macro avg       0.75      0.75      0.73     27761\n",
      "weighted avg       0.77      0.73      0.73     27761\n",
      "\n",
      "Getting dependency and POS tags...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentence2pos tags:: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 14114/14114 [01:05<00:00, 215.14it/s]\n",
      "Parent POS tags:: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 14114/14114 [01:04<00:00, 218.20it/s]\n",
      "sentence2tag tags:: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 14114/14114 [01:05<00:00, 215.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Tags: complete!\n",
      "Getting dependency and DEP tags...\n",
      "DEP Tags: complete!\n",
      "Creating BERT Embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 14114/14114 [00:02<00:00, 5884.17it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 14114/14114 [00:00<00:00, 377170.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running classification:\n",
      "442/442 [==============================] - 325s 735ms/step\n",
      "Done.\n",
      "\u001b[1;30;43mMultiCW Noisy Part:\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.50      0.62      7997\n",
      "           1       0.57      0.85      0.68      6117\n",
      "\n",
      "    accuracy                           0.65     14114\n",
      "   macro avg       0.69      0.67      0.65     14114\n",
      "weighted avg       0.71      0.65      0.65     14114\n",
      "\n",
      "Getting dependency and POS tags...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentence2pos tags:: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 13647/13647 [00:50<00:00, 272.06it/s]\n",
      "Parent POS tags:: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 13647/13647 [00:48<00:00, 278.57it/s]\n",
      "sentence2tag tags:: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 13647/13647 [00:48<00:00, 278.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Tags: complete!\n",
      "Getting dependency and DEP tags...\n",
      "DEP Tags: complete!\n",
      "Creating BERT Embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13647/13647 [00:01<00:00, 9992.04it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13647/13647 [00:00<00:00, 412960.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running classification:\n",
      "427/427 [==============================] - 305s 715ms/step\n",
      "Done.\n",
      "\u001b[1;30;43mMultiCW Structured Part:\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.78      0.83      8000\n",
      "           1       0.73      0.87      0.80      5647\n",
      "\n",
      "    accuracy                           0.82     13647\n",
      "   macro avg       0.82      0.83      0.82     13647\n",
      "weighted avg       0.83      0.82      0.82     13647\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'{h_green}LESA model:{h_stop}')\n",
    "detector = LESAClaimModel()\n",
    "\n",
    "if not detector.load_model(model_name=f'lesa-multicw-2e6-5e'):\n",
    "    print(f'{h_yellow}No model found. Initiating fine-tuning:{h_stop}')\n",
    "    # Note: Works well with a small learning rate (e.g. 3e-6)\n",
    "    detector.train_model(multicw_train, multicw_dev, epochs=5, learn_rate=2e-6, lang='en', model_name=f'lesa-multicw')\n",
    "\n",
    "print(f'{h_green}MultiCW overall:{h_stop}')\n",
    "_, report = detector.detect_claims(multicw_ood)\n",
    "print(report)\n",
    "\n",
    "test_noisy = multicw_ood.loc[multicw_ood['style']=='noisy']\n",
    "_, report = detector.detect_claims(test_noisy, verbose=False)\n",
    "print(f'{h_yellow}MultiCW Noisy Part:{h_stop}')\n",
    "print(report)\n",
    "\n",
    "test_struc = multicw_ood.loc[multicw_ood['style']=='struc']\n",
    "_, report = detector.detect_claims(test_struc, verbose=False)\n",
    "print(f'{h_yellow}MultiCW Structured Part:{h_stop}')\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "modelId": 2834,
     "modelInstanceId": 4721,
     "sourceId": 6189,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 2820,
     "modelInstanceId": 4688,
     "sourceId": 6067,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "MultiCW-lesa",
   "language": "python",
   "name": "multicw-lesa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0abbc91f30b04bd3b464ab626caa4ef6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2511f785d020410e851c8f198278c7da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DropdownModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DropdownModel",
      "_options_labels": [
       "cpu",
       "gpu"
      ],
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "DropdownView",
      "description": "Storage mode:",
      "description_tooltip": null,
      "disabled": false,
      "index": 1,
      "layout": "IPY_MODEL_8af9da3904434c8db72bf48038475c9e",
      "style": "IPY_MODEL_0abbc91f30b04bd3b464ab626caa4ef6"
     }
    },
    "2c2931510812437899b50874520958b0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "353fd4c3ba06412d9431ead32ef52b9c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "IntSliderModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntSliderModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "IntSliderView",
      "continuous_update": true,
      "description": "Batch size:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_8642bd2f2a174d2eafd1ae06aaa494e5",
      "max": 32,
      "min": 1,
      "orientation": "horizontal",
      "readout": true,
      "readout_format": "d",
      "step": 1,
      "style": "IPY_MODEL_6305e85181ee4afa84499a116c911b1c",
      "value": 8
     }
    },
    "5b36326a73a84c80aadbe97684b4083c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bfac425cbea74dbca85bc28aec8fca84",
       "IPY_MODEL_353fd4c3ba06412d9431ead32ef52b9c",
       "IPY_MODEL_e2a27094e6ab478e887d6dbd0d166255",
       "IPY_MODEL_c498aabcc4754ea69cc7939e23b295f2",
       "IPY_MODEL_f0a443c22c71401cadcd0ed9d720a50b",
       "IPY_MODEL_2511f785d020410e851c8f198278c7da"
      ],
      "layout": "IPY_MODEL_f151a00a84a444a2ac3dde95d6449f76"
     }
    },
    "6305e85181ee4afa84499a116c911b1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "SliderStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "SliderStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": "",
      "handle_color": null
     }
    },
    "6d2245fa0357414793ec484e42a407ce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "702fc0ae0e9646e195974358ada8698e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "SliderStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "SliderStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": "",
      "handle_color": null
     }
    },
    "8642bd2f2a174d2eafd1ae06aaa494e5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8988b2e3116348faae276ec36bf6b2af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8af9da3904434c8db72bf48038475c9e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bfac425cbea74dbca85bc28aec8fca84": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DropdownModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DropdownModel",
      "_options_labels": [
       "mDeBERTa",
       "XLM-RoBERTa",
       "LESA"
      ],
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "DropdownView",
      "description": "Model:",
      "description_tooltip": null,
      "disabled": false,
      "index": 0,
      "layout": "IPY_MODEL_ecacd507e05b492dbdcfd924c6c7e039",
      "style": "IPY_MODEL_8988b2e3116348faae276ec36bf6b2af"
     }
    },
    "c1fa2f69f0a147e891184b3d41decae5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "SliderStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "SliderStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": "",
      "handle_color": null
     }
    },
    "c498aabcc4754ea69cc7939e23b295f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatLogSliderModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatLogSliderModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "FloatLogSliderView",
      "base": 10,
      "continuous_update": true,
      "description": "Learning Rate:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_6d2245fa0357414793ec484e42a407ce",
      "max": -1,
      "min": -10,
      "orientation": "horizontal",
      "readout": true,
      "readout_format": ".1e",
      "step": 0.1,
      "style": "IPY_MODEL_cf376d4917444367af900a2ea6fbfbd1",
      "value": 3e-05
     }
    },
    "cf376d4917444367af900a2ea6fbfbd1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "SliderStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "SliderStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": "initial",
      "handle_color": null
     }
    },
    "e2a27094e6ab478e887d6dbd0d166255": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "IntSliderModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntSliderModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "IntSliderView",
      "continuous_update": true,
      "description": "Batch chunk size:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_fb777cd857e848febd846dabb6f351e4",
      "max": 32,
      "min": 1,
      "orientation": "horizontal",
      "readout": true,
      "readout_format": "d",
      "step": 1,
      "style": "IPY_MODEL_c1fa2f69f0a147e891184b3d41decae5",
      "value": 8
     }
    },
    "ecacd507e05b492dbdcfd924c6c7e039": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f0a443c22c71401cadcd0ed9d720a50b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatSliderModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatSliderModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "FloatSliderView",
      "continuous_update": true,
      "description": "Classifier threshold:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_2c2931510812437899b50874520958b0",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "readout": true,
      "readout_format": ".2f",
      "step": 1e-05,
      "style": "IPY_MODEL_702fc0ae0e9646e195974358ada8698e",
      "value": 0.5
     }
    },
    "f151a00a84a444a2ac3dde95d6449f76": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb777cd857e848febd846dabb6f351e4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
