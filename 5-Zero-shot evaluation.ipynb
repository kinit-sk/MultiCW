{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63d3e05b-4195-4df0-b1e8-4014bd91b178",
   "metadata": {},
   "source": [
    "# LLM zero-shot Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c89aeaa-6ab2-451e-9fba-044033a889c7",
   "metadata": {
    "id": "3eb7fd0d-9d7e-43be-9257-644125af64e9"
   },
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff1079b-6248-446f-ba94-a8f2a8c090f6",
   "metadata": {},
   "source": [
    "#### Setup project paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86c6994e-ed69-4417-ac42-1f6a9dd4c025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from os.path import join, exists\n",
    "from py_markdown_table.markdown_table import markdown_table\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Enable tqdm for pandas\n",
    "tqdm.pandas()\n",
    "\n",
    "# ANSI Highlighting: https://stackoverflow.com/a/21786287\n",
    "h_red = '\\x1b[1;30;41m'\n",
    "h_green = '\\x1b[1;30;42m'\n",
    "h_yellow = '\\x1b[1;30;43m'\n",
    "h_stop = '\\x1b[0m'\n",
    "\n",
    "## Setup project paths:\n",
    "project_path = os.getcwd()\n",
    "models_path = join(project_path, \"Models\")\n",
    "\n",
    "datasets_path = join(project_path, \"Source datasets\")\n",
    "multicw_path = join(project_path, 'Final-dataset')\n",
    "multiclaim_path = join(datasets_path, \"MultiClaim\")\n",
    "lesa_dst_dir = join(datasets_path, 'LESA-EACL-2021')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1300db-cee7-495c-9355-d851579e696f",
   "metadata": {},
   "source": [
    "## Results\n",
    "Loading theresults of zero-shot evaluation of selected LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cdf1dd9-8a5b-45dd-b4be-47a23aae2499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;42mLanguage: ar:\u001b[0m\n",
      "\u001b[1;30;43mNemotron-4 340B (CoT):\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.43      0.55       599\n",
      "         1.0       0.60      0.85      0.70       599\n",
      "\n",
      "    accuracy                           0.64      1198\n",
      "   macro avg       0.67      0.64      0.63      1198\n",
      "weighted avg       0.67      0.64      0.63      1198\n",
      "\n",
      "\u001b[1;30;43mClaude 3.5 Haiku (CoT):\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.26      0.37       599\n",
      "         1.0       0.54      0.89      0.68       599\n",
      "\n",
      "    accuracy                           0.57      1198\n",
      "   macro avg       0.62      0.57      0.52      1198\n",
      "weighted avg       0.62      0.57      0.52      1198\n",
      "\n",
      "\u001b[1;30;43mLlama3.1:70b (CoT):\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.36      0.46       599\n",
      "         1.0       0.56      0.80      0.65       599\n",
      "\n",
      "    accuracy                           0.58      1198\n",
      "   macro avg       0.60      0.58      0.56      1198\n",
      "weighted avg       0.60      0.58      0.56      1198\n",
      "\n",
      "\u001b[1;30;42mLanguage: bg:\u001b[0m\n",
      "\u001b[1;30;43mNemotron-4 340B (CoT):\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.55      0.62       530\n",
      "         1.0       0.63      0.76      0.69       530\n",
      "\n",
      "    accuracy                           0.66      1060\n",
      "   macro avg       0.66      0.66      0.65      1060\n",
      "weighted avg       0.66      0.66      0.65      1060\n",
      "\n",
      "\u001b[1;30;43mClaude 3.5 Haiku (CoT):\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.39      0.47       530\n",
      "         1.0       0.54      0.71      0.61       530\n",
      "\n",
      "    accuracy                           0.55      1060\n",
      "   macro avg       0.56      0.55      0.54      1060\n",
      "weighted avg       0.56      0.55      0.54      1060\n",
      "\n",
      "\u001b[1;30;43mLlama3.1:70b (CoT):\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.42      0.48       530\n",
      "         1.0       0.53      0.65      0.59       530\n",
      "\n",
      "    accuracy                           0.54      1060\n",
      "   macro avg       0.54      0.54      0.53      1060\n",
      "weighted avg       0.54      0.54      0.53      1060\n",
      "\n",
      "\u001b[1;30;42mLanguage: bn:\u001b[0m\n",
      "\u001b[1;30;43mNemotron-4 340B (CoT):\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.80      0.81       465\n",
      "         1.0       0.80      0.82      0.81       465\n",
      "\n",
      "    accuracy                           0.81       930\n",
      "   macro avg       0.81      0.81      0.81       930\n",
      "weighted avg       0.81      0.81      0.81       930\n",
      "\n",
      "\u001b[1;30;43mClaude 3.5 Haiku (CoT):\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.67      0.74       465\n",
      "         1.0       0.72      0.87      0.79       465\n",
      "\n",
      "    accuracy                           0.77       930\n",
      "   macro avg       0.78      0.77      0.77       930\n",
      "weighted avg       0.78      0.77      0.77       930\n",
      "\n",
      "\u001b[1;30;43mLlama3.1:70b (CoT):\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.85      0.76       465\n",
      "         1.0       0.80      0.63      0.71       465\n",
      "\n",
      "    accuracy                           0.74       930\n",
      "   macro avg       0.75      0.74      0.74       930\n",
      "weighted avg       0.75      0.74      0.74       930\n",
      "\n",
      "\u001b[1;30;42mLanguage: cs:\u001b[0m\n",
      "\u001b[1;30;43mNemotron-4 340B (CoT):\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.78      0.80       596\n",
      "         1.0       0.79      0.85      0.82       596\n",
      "\n",
      "    accuracy                           0.81      1192\n",
      "   macro avg       0.81      0.81      0.81      1192\n",
      "weighted avg       0.81      0.81      0.81      1192\n",
      "\n",
      "\u001b[1;30;43mClaude 3.5 Haiku (CoT):\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.70      0.74       596\n",
      "         1.0       0.73      0.81      0.77       596\n",
      "\n",
      "    accuracy                           0.76      1192\n",
      "   macro avg       0.76      0.76      0.76      1192\n",
      "weighted avg       0.76      0.76      0.76      1192\n",
      "\n",
      "\u001b[1;30;43mLlama3.1:70b (CoT):\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.81      0.78       596\n",
      "         1.0       0.80      0.74      0.76       596\n",
      "\n",
      "    accuracy                           0.77      1192\n",
      "   macro avg       0.77      0.77      0.77      1192\n",
      "weighted avg       0.77      0.77      0.77      1192\n",
      "\n",
      "\u001b[1;30;42mLanguage: de:\u001b[0m\n",
      "\u001b[1;30;43mNemotron-4 340B (CoT):\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.82      0.86       596\n",
      "         1.0       0.84      0.91      0.87       596\n",
      "\n",
      "    accuracy                           0.87      1192\n",
      "   macro avg       0.87      0.87      0.87      1192\n",
      "weighted avg       0.87      0.87      0.87      1192\n",
      "\n",
      "\u001b[1;30;43mClaude 3.5 Haiku (CoT):\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.74      0.81       596\n",
      "         1.0       0.78      0.90      0.84       596\n",
      "\n",
      "    accuracy                           0.82      1192\n",
      "   macro avg       0.83      0.82      0.82      1192\n",
      "weighted avg       0.83      0.82      0.82      1192\n",
      "\n",
      "\u001b[1;30;43mLlama3.1:70b (CoT):\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.79      0.81       596\n",
      "         1.0       0.80      0.83      0.81       596\n",
      "\n",
      "    accuracy                           0.81      1192\n",
      "   macro avg       0.81      0.81      0.81      1192\n",
      "weighted avg       0.81      0.81      0.81      1192\n",
      "\n",
      "\u001b[1;30;42mLanguage: en:\u001b[0m\n",
      "\u001b[1;30;43mNemotron-4 340B (CoT):\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.71      0.74       600\n",
      "         1.0       0.73      0.80      0.77       600\n",
      "\n",
      "    accuracy                           0.76      1200\n",
      "   macro avg       0.76      0.76      0.76      1200\n",
      "weighted avg       0.76      0.76      0.76      1200\n",
      "\n",
      "\u001b[1;30;43mClaude 3.5 Haiku (CoT):\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.53      0.61       600\n",
      "         1.0       0.63      0.78      0.69       600\n",
      "\n",
      "    accuracy                           0.66      1200\n",
      "   macro avg       0.67      0.66      0.65      1200\n",
      "weighted avg       0.67      0.66      0.65      1200\n",
      "\n",
      "\u001b[1;30;43mLlama3.1:70b (CoT):\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.52      0.60       600\n",
      "         1.0       0.62      0.79      0.69       600\n",
      "\n",
      "    accuracy                           0.65      1200\n",
      "   macro avg       0.66      0.65      0.65      1200\n",
      "weighted avg       0.66      0.65      0.65      1200\n",
      "\n",
      "\u001b[1;30;42mLanguage: es:\u001b[0m\n",
      "\u001b[1;30;43mNemotron-4 340B (CoT):\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.59      0.70       599\n",
      "         1.0       0.69      0.90      0.78       599\n",
      "\n",
      "    accuracy                           0.74      1198\n",
      "   macro avg       0.77      0.74      0.74      1198\n",
      "weighted avg       0.77      0.74      0.74      1198\n",
      "\n",
      "\u001b[1;30;43mClaude 3.5 Haiku (CoT):\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.56      0.67       599\n",
      "         1.0       0.67      0.90      0.77       599\n",
      "\n",
      "    accuracy                           0.73      1198\n",
      "   macro avg       0.76      0.73      0.72      1198\n",
      "weighted avg       0.76      0.73      0.72      1198\n",
      "\n",
      "\u001b[1;30;43mLlama3.1:70b (CoT):\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.61      0.69       599\n",
      "         1.0       0.68      0.85      0.76       599\n",
      "\n",
      "    accuracy                           0.73      1198\n",
      "   macro avg       0.74      0.73      0.72      1198\n",
      "weighted avg       0.74      0.73      0.72      1198\n",
      "\n",
      "\u001b[1;30;42mLanguage: fr:\u001b[0m\n",
      "\u001b[1;30;43mNemotron-4 340B (CoT):\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.82      0.84       597\n",
      "         1.0       0.83      0.87      0.85       597\n",
      "\n",
      "    accuracy                           0.85      1194\n",
      "   macro avg       0.85      0.85      0.85      1194\n",
      "weighted avg       0.85      0.85      0.85      1194\n",
      "\n",
      "\u001b[1;30;43mClaude 3.5 Haiku (CoT):\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.71      0.79       597\n",
      "         1.0       0.76      0.91      0.83       597\n",
      "\n",
      "    accuracy                           0.81      1194\n",
      "   macro avg       0.82      0.81      0.81      1194\n",
      "weighted avg       0.82      0.81      0.81      1194\n",
      "\n",
      "\u001b[1;30;43mLlama3.1:70b (CoT):\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.81      0.79       597\n",
      "         1.0       0.80      0.77      0.78       597\n",
      "\n",
      "    accuracy                           0.79      1194\n",
      "   macro avg       0.79      0.79      0.79      1194\n",
      "weighted avg       0.79      0.79      0.79      1194\n",
      "\n",
      "\u001b[1;30;42mLanguage: hi:\u001b[0m\n",
      "\u001b[1;30;43mNemotron-4 340B (CoT):\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.82      0.85       597\n",
      "         1.0       0.83      0.89      0.86       597\n",
      "\n",
      "    accuracy                           0.85      1194\n",
      "   macro avg       0.86      0.85      0.85      1194\n",
      "weighted avg       0.86      0.85      0.85      1194\n",
      "\n",
      "\u001b[1;30;43mClaude 3.5 Haiku (CoT):\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.64      0.74       597\n",
      "         1.0       0.72      0.91      0.80       597\n",
      "\n",
      "    accuracy                           0.78      1194\n",
      "   macro avg       0.80      0.78      0.77      1194\n",
      "weighted avg       0.80      0.78      0.77      1194\n",
      "\n",
      "\u001b[1;30;43mLlama3.1:70b (CoT):\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.89      0.82       597\n",
      "         1.0       0.87      0.70      0.78       597\n",
      "\n",
      "    accuracy                           0.80      1194\n",
      "   macro avg       0.81      0.80      0.80      1194\n",
      "weighted avg       0.81      0.80      0.80      1194\n",
      "\n",
      "\u001b[1;30;42mLanguage: pl:\u001b[0m\n",
      "\u001b[1;30;43mNemotron-4 340B (CoT):\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.81      0.86       597\n",
      "         1.0       0.83      0.93      0.88       597\n",
      "\n",
      "    accuracy                           0.87      1194\n",
      "   macro avg       0.87      0.87      0.87      1194\n",
      "weighted avg       0.87      0.87      0.87      1194\n",
      "\n",
      "\u001b[1;30;43mClaude 3.5 Haiku (CoT):\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.75      0.82       597\n",
      "         1.0       0.78      0.91      0.84       597\n",
      "\n",
      "    accuracy                           0.83      1194\n",
      "   macro avg       0.84      0.83      0.83      1194\n",
      "weighted avg       0.84      0.83      0.83      1194\n",
      "\n",
      "\u001b[1;30;43mLlama3.1:70b (CoT):\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.86      0.84       597\n",
      "         1.0       0.85      0.81      0.83       597\n",
      "\n",
      "    accuracy                           0.83      1194\n",
      "   macro avg       0.83      0.83      0.83      1194\n",
      "weighted avg       0.83      0.83      0.83      1194\n",
      "\n",
      "\u001b[1;30;42mLanguage: pt:\u001b[0m\n",
      "\u001b[1;30;43mNemotron-4 340B (CoT):\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.79      0.82       597\n",
      "         1.0       0.80      0.86      0.83       597\n",
      "\n",
      "    accuracy                           0.82      1194\n",
      "   macro avg       0.82      0.82      0.82      1194\n",
      "weighted avg       0.82      0.82      0.82      1194\n",
      "\n",
      "\u001b[1;30;43mClaude 3.5 Haiku (CoT):\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.73      0.80       597\n",
      "         1.0       0.77      0.90      0.83       597\n",
      "\n",
      "    accuracy                           0.81      1194\n",
      "   macro avg       0.82      0.81      0.81      1194\n",
      "weighted avg       0.82      0.81      0.81      1194\n",
      "\n",
      "\u001b[1;30;43mLlama3.1:70b (CoT):\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.76      0.78       597\n",
      "         1.0       0.77      0.82      0.80       597\n",
      "\n",
      "    accuracy                           0.79      1194\n",
      "   macro avg       0.79      0.79      0.79      1194\n",
      "weighted avg       0.79      0.79      0.79      1194\n",
      "\n",
      "\u001b[1;30;42mLanguage: ru:\u001b[0m\n",
      "\u001b[1;30;43mNemotron-4 340B (CoT):\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.78      0.84       597\n",
      "         1.0       0.81      0.94      0.87       597\n",
      "\n",
      "    accuracy                           0.86      1194\n",
      "   macro avg       0.87      0.86      0.86      1194\n",
      "weighted avg       0.87      0.86      0.86      1194\n",
      "\n",
      "\u001b[1;30;43mClaude 3.5 Haiku (CoT):\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.73      0.81       597\n",
      "         1.0       0.78      0.93      0.85       597\n",
      "\n",
      "    accuracy                           0.83      1194\n",
      "   macro avg       0.85      0.83      0.83      1194\n",
      "weighted avg       0.85      0.83      0.83      1194\n",
      "\n",
      "\u001b[1;30;43mLlama3.1:70b (CoT):\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.79      0.84       597\n",
      "         1.0       0.81      0.90      0.85       597\n",
      "\n",
      "    accuracy                           0.85      1194\n",
      "   macro avg       0.85      0.85      0.85      1194\n",
      "weighted avg       0.85      0.85      0.85      1194\n",
      "\n",
      "\u001b[1;30;42mLanguage: sk:\u001b[0m\n",
      "\u001b[1;30;43mNemotron-4 340B (CoT):\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.78      0.83       596\n",
      "         1.0       0.80      0.89      0.85       596\n",
      "\n",
      "    accuracy                           0.84      1192\n",
      "   macro avg       0.84      0.84      0.84      1192\n",
      "weighted avg       0.84      0.84      0.84      1192\n",
      "\n",
      "\u001b[1;30;43mClaude 3.5 Haiku (CoT):\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.76      0.79       596\n",
      "         1.0       0.78      0.82      0.80       596\n",
      "\n",
      "    accuracy                           0.79      1192\n",
      "   macro avg       0.79      0.79      0.79      1192\n",
      "weighted avg       0.79      0.79      0.79      1192\n",
      "\n",
      "\u001b[1;30;43mLlama3.1:70b (CoT):\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.84      0.77       596\n",
      "         1.0       0.80      0.65      0.72       596\n",
      "\n",
      "    accuracy                           0.75      1192\n",
      "   macro avg       0.75      0.75      0.74      1192\n",
      "weighted avg       0.75      0.75      0.74      1192\n",
      "\n",
      "\u001b[1;30;42mLanguage: tr:\u001b[0m\n",
      "\u001b[1;30;43mNemotron-4 340B (CoT):\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.49      0.62       592\n",
      "         1.0       0.64      0.91      0.75       592\n",
      "\n",
      "    accuracy                           0.70      1184\n",
      "   macro avg       0.75      0.70      0.69      1184\n",
      "weighted avg       0.75      0.70      0.69      1184\n",
      "\n",
      "\u001b[1;30;43mClaude 3.5 Haiku (CoT):\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.39      0.52       592\n",
      "         1.0       0.60      0.92      0.72       592\n",
      "\n",
      "    accuracy                           0.65      1184\n",
      "   macro avg       0.71      0.65      0.62      1184\n",
      "weighted avg       0.71      0.65      0.62      1184\n",
      "\n",
      "\u001b[1;30;43mLlama3.1:70b (CoT):\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.46      0.56       592\n",
      "         1.0       0.61      0.83      0.70       592\n",
      "\n",
      "    accuracy                           0.64      1184\n",
      "   macro avg       0.67      0.64      0.63      1184\n",
      "weighted avg       0.67      0.64      0.63      1184\n",
      "\n",
      "\u001b[1;30;42mLanguage: uk:\u001b[0m\n",
      "\u001b[1;30;43mNemotron-4 340B (CoT):\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.77      0.82       595\n",
      "         1.0       0.80      0.89      0.84       595\n",
      "\n",
      "    accuracy                           0.83      1190\n",
      "   macro avg       0.84      0.83      0.83      1190\n",
      "weighted avg       0.84      0.83      0.83      1190\n",
      "\n",
      "\u001b[1;30;43mClaude 3.5 Haiku (CoT):\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.73      0.78       595\n",
      "         1.0       0.76      0.87      0.81       595\n",
      "\n",
      "    accuracy                           0.80      1190\n",
      "   macro avg       0.80      0.80      0.80      1190\n",
      "weighted avg       0.80      0.80      0.80      1190\n",
      "\n",
      "\u001b[1;30;43mLlama3.1:70b (CoT):\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.73      0.78       595\n",
      "         1.0       0.76      0.87      0.81       595\n",
      "\n",
      "    accuracy                           0.80      1190\n",
      "   macro avg       0.80      0.80      0.80      1190\n",
      "weighted avg       0.80      0.80      0.80      1190\n",
      "\n",
      "\u001b[1;30;42mLanguage: zh:\u001b[0m\n",
      "\u001b[1;30;43mNemotron-4 340B (CoT):\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.71      0.77       517\n",
      "         1.0       0.75      0.87      0.80       517\n",
      "\n",
      "    accuracy                           0.79      1034\n",
      "   macro avg       0.80      0.79      0.79      1034\n",
      "weighted avg       0.80      0.79      0.79      1034\n",
      "\n",
      "\u001b[1;30;43mClaude 3.5 Haiku (CoT):\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.71      0.78       517\n",
      "         1.0       0.75      0.90      0.82       517\n",
      "\n",
      "    accuracy                           0.80      1034\n",
      "   macro avg       0.81      0.80      0.80      1034\n",
      "weighted avg       0.81      0.80      0.80      1034\n",
      "\n",
      "\u001b[1;30;43mLlama3.1:70b (CoT):\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.80      0.80       517\n",
      "         1.0       0.80      0.80      0.80       517\n",
      "\n",
      "    accuracy                           0.80      1034\n",
      "   macro avg       0.80      0.80      0.80      1034\n",
      "weighted avg       0.80      0.80      0.80      1034\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Path to the folder with label CSVs\n",
    "labels_folder = join('Results')\n",
    "\n",
    "# Load your main dataframe\n",
    "multicw_test = pd.read_csv(join('Results', 'multicw-test.csv'))\n",
    "nemotron = pd.read_csv(join('Results', 'nemotron_4_340b_CoT_multicw_test.csv'))\n",
    "multicw_test['nemotron_4_340b_CoT'] = nemotron['answer']\n",
    "columns = multicw_test.columns\n",
    "\n",
    "# print(columns)\n",
    "columns = ['fc_worthy_CoT_CLEF_on_Q_claude-3-5-haiku-20241022', 'fc_worthy_CoT_CLEF_on_Q_llama3.1:70b']\n",
    "\n",
    "languages = multicw_test['lang'].unique()\n",
    "languages.sort()\n",
    "\n",
    "for lang in languages:\n",
    "    print(f'{h_green}Language: {lang}:{h_stop}')\n",
    "    # Language specific subset\n",
    "    multicw_lang = multicw_test[multicw_test['lang'] == lang]\n",
    "\n",
    "    ground_truth = multicw_lang['label']\n",
    "    results = multicw_lang['nemotron_4_340b_CoT']\n",
    "\n",
    "    report = classification_report(ground_truth, results, output_dict=True)\n",
    "    report_str = str(classification_report(ground_truth, results))\n",
    "    \n",
    "    print(f'{h_yellow}Nemotron-4 340B (CoT):{h_stop}')\n",
    "    print(report_str)\n",
    "\n",
    "    \n",
    "    for column in columns:\n",
    "        ground_truth = multicw_lang['label']\n",
    "        results = multicw_lang[column]\n",
    "    \n",
    "        report = classification_report(ground_truth, results, output_dict=True)\n",
    "        report_str = str(classification_report(ground_truth, results))\n",
    "        if column == 'fc_worthy_CoT_CLEF_on_Q_claude-3-5-haiku-20241022':\n",
    "            column = 'Claude 3.5 Haiku (CoT)'\n",
    "        if column == 'fc_worthy_CoT_CLEF_on_Q_llama3.1:70b':\n",
    "            column = 'Llama3.1:70b (CoT)'\n",
    "        print(f'{h_yellow}{column}:{h_stop}')\n",
    "        print(report_str)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MultiCW-finetune",
   "language": "python",
   "name": "multicw-finetune"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
